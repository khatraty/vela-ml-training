{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎓 Session 1 - Introduction à l'IA et au Machine Learning\n",
    "## Solutions avec Cas Pratique : Prédiction BAC Mauritanie 2022\n",
    "\n",
    "**Formation IA & ML - SupNum Nouakchott**  \n",
    "**Formateur:** Mohamed Beydia - Vela Learning  \n",
    "**Dataset:** BAC Mauritanie 2022 Predictive Modeling Challenge\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Objectifs de la session\n",
    "\n",
    "À la fin de cette session, vous serez capables de :\n",
    "- [x] Définir l'Intelligence Artificielle, le Machine Learning et le Deep Learning\n",
    "- [x] Distinguer l'IA symbolique de l'IA statistique\n",
    "- [x] Comprendre la différence entre IA analytique et générative\n",
    "- [x] Identifier les trois familles principales du ML\n",
    "- [x] Décrire le workflow standard d'un projet ML\n",
    "- [x] Reconnaître des cas d'usage concrets d'IA\n",
    "- [x] **BONUS:** Analyser un dataset réel et créer votre première prédiction ML !\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 1. Qu'est-ce que l'Intelligence Artificielle ?\n",
    "\n",
    "### 📝 Solutions - Définitions\n",
    "\n",
    "**Intelligence Artificielle (IA)** : Capacité d'une machine à imiter l'intelligence humaine pour résoudre des problèmes, prendre des décisions et s'adapter à de nouvelles situations.\n",
    "\n",
    "**Machine Learning (ML)** : Sous-domaine de l'IA qui permet aux machines d'apprendre automatiquement à partir de données sans être explicitement programmées pour chaque tâche.\n",
    "\n",
    "**Deep Learning (DL)** : Sous-domaine du ML utilisant des réseaux de neurones artificiels profonds (multiples couches) pour résoudre des problèmes complexes.\n",
    "\n",
    "### 🔗 Relation hiérarchique :\n",
    "**IA ⊃ ML ⊃ Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 2. Types d'Intelligence Artificielle\n",
    "\n",
    "### 📝 Solutions - IA Symbolique vs IA Statistique\n",
    "\n",
    "1. Un système expert médical avec des règles if-then → **IA Symbolique**\n",
    "2. Un modèle de reconnaissance d'images → **IA Statistique**\n",
    "3. Un chatbot basé sur des arbres de décision → **IA Symbolique**\n",
    "4. Un algorithme de recommandation Netflix → **IA Statistique**\n",
    "5. Un système de diagnostic automatique → **IA Statistique** (généralement)\n",
    "\n",
    "**Notre cas BAC Mauritanie** : IA Statistique - nous allons utiliser des données pour prédire les résultats !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 3. IA Analytique vs IA Générative\n",
    "\n",
    "### 📝 Solutions - Classification des applications\n",
    "\n",
    "| Application | Type IA | Justification |\n",
    "|-------------|---------|---------------|\n",
    "| ChatGPT | **Générative** | Crée du nouveau contenu textuel |\n",
    "| Détection de spam | **Analytique** | Analyse et classifie des emails existants |\n",
    "| DALL-E | **Générative** | Génère de nouvelles images |\n",
    "| Prédiction de ventes | **Analytique** | Analyse les données historiques |\n",
    "| GitHub Copilot | **Générative** | Génère du code |\n",
    "| Analyse de sentiments | **Analytique** | Classifie les émotions dans le texte |\n",
    "\n",
    "**Notre projet BAC** : IA Analytique - nous analysons les données pour prédire les résultats des étudiants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 4. Les Familles du Machine Learning\n",
    "\n",
    "### 📝 Solutions - Familles ML\n",
    "\n",
    "| Famille ML | Définition | Exemple d'algorithme | Cas d'usage |\n",
    "|------------|------------|---------------------|-------------|\n",
    "| **Supervisé** | Apprentissage avec données étiquetées | Régression linéaire, Random Forest | Prédiction BAC, détection spam |\n",
    "| **Non supervisé** | Apprentissage sans étiquettes | K-means, PCA | Segmentation clients, compression |\n",
    "| **Par renforcement** | Apprentissage par récompenses/punitions | Q-learning, Policy Gradient | Jeux, robotique, trading |\n",
    "\n",
    "**Notre projet BAC utilisera l'apprentissage supervisé** car nous avons les notes (étiquettes) pour prédire les résultats futurs !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ 5. Workflow Machine Learning\n",
    "\n",
    "### 📝 Solutions - Workflow ML\n",
    "\n",
    "**Ordre correct :**\n",
    "1. **Définition du problème** - Que voulons-nous prédire ?\n",
    "2. **Collecte des données** - Rassembler les données BAC\n",
    "3. **Préparation des données** - Nettoyage, transformation\n",
    "4. **Sélection de l'algorithme** - Choisir le bon modèle ML\n",
    "5. **Entraînement du modèle** - Apprendre des données\n",
    "6. **Évaluation du modèle** - Mesurer la performance\n",
    "7. **Déploiement** - Mise en production\n",
    "8. **Monitoring et maintenance** - Surveillance continue\n",
    "\n",
    "**Nous allons suivre ce workflow pour le dataset BAC !** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌍 6. Cas d'Usage de l'IA\n",
    "\n",
    "### 📝 Solutions - Cas d'usage par secteur\n",
    "\n",
    "#### 🎓 Éducation\n",
    "- **Prédiction de réussite scolaire** (notre cas !)\n",
    "- Personnalisation des parcours d'apprentissage\n",
    "- Détection précoce du décrochage scolaire\n",
    "- Correction automatique et feedback intelligent\n",
    "\n",
    "#### 💼 Business/Finance\n",
    "- Détection de fraude bancaire\n",
    "- Analyse des risques de crédit\n",
    "- Trading algorithmique\n",
    "- Optimisation des prix dynamiques\n",
    "\n",
    "#### 🏥 Santé\n",
    "- Diagnostic médical assisté par IA\n",
    "- Découverte de médicaments\n",
    "- Analyse d'imagerie médicale\n",
    "- Prédiction d'épidémies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💻 7. PROJET PRATIQUE : Analyse BAC Mauritanie 2022\n",
    "\n",
    "### 🎯 Notre Défi Kaggle\n",
    "**Objectif :** Prédire les résultats du BAC 2022 en Mauritanie à partir des données des candidats\n",
    "\n",
    "**Type de problème :** Classification supervisée  \n",
    "**Métrique :** Accuracy, Precision, Recall\n",
    "\n",
    "Commençons par explorer nos données !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import des librairies essentielles pour notre projet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour les graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Librairies importées avec succès !\")\n",
    "print(f\"📊 Pandas version: {pd.__version__}\")\n",
    "print(f\"🔢 NumPy version: {np.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extraction et chargement des données BAC Mauritanie\n",
    "import os\n",
    "\n",
    "# Chemin vers le fichier zip\n",
    "zip_path = \"../../data/external/bac-mauritanie-2022-predictive-modeling-challeng.zip\"\n",
    "extract_path = \"../../data/raw/bac_mauritanie/\"\n",
    "\n",
    "# Créer le dossier d'extraction s'il n'existe pas\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extraire les données\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"✅ Données extraites avec succès !\")\n",
    "    \n",
    "    # Lister les fichiers extraits\n",
    "    files = os.listdir(extract_path)\n",
    "    print(\"📁 Fichiers disponibles:\")\n",
    "    for file in files:\n",
    "        print(f\"  - {file}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de l'extraction: {e}\")\n",
    "    print(\"Vérifiez que le fichier zip existe dans data/external/\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Chargement des datasets\n",
    "try:\n",
    "    # Chargement des données d'entraînement et de test\n",
    "    train_df = pd.read_csv(f\"{extract_path}/train.csv\")\n",
    "    test_df = pd.read_csv(f\"{extract_path}/test.csv\")\n",
    "    sample_submission = pd.read_csv(f\"{extract_path}/sample_template.csv\")\n",
    "    \n",
    "    print(\"✅ Datasets chargés avec succès !\")\n",
    "    print(f\"📊 Données d'entraînement: {train_df.shape[0]} lignes, {train_df.shape[1]} colonnes\")\n",
    "    print(f\"📊 Données de test: {test_df.shape[0]} lignes, {test_df.shape[1]} colonnes\")\n",
    "    print(f\"📊 Template de soumission: {sample_submission.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors du chargement: {e}\")\n",
    "    print(\"Les fichiers CSV doivent être extraits dans le dossier raw/bac_mauritanie/\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 🔍 ÉTAPE 1 : EXPLORATION DES DONNÉES (EDA)\n",
    "print(\"🔍 === EXPLORATION DES DONNÉES BAC MAURITANIE 2022 ===\")\n",
    "print()\n",
    "\n",
    "# Aperçu des données d'entraînement\n",
    "print(\"📋 Aperçu des données d'entraînement:\")\n",
    "print(train_df.head())\n",
    "print()\n",
    "\n",
    "# Informations sur les colonnes\n",
    "print(\"📊 Informations sur les colonnes:\")\n",
    "print(train_df.info())\n",
    "print()\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"📈 Statistiques descriptives:\")\n",
    "print(train_df.describe())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyse de la variable cible (Decision)\n",
    "print(\"🎯 ANALYSE DE LA VARIABLE CIBLE : 'Decision'\")\n",
    "print()\n",
    "\n",
    "# Distribution de la variable cible\n",
    "decision_counts = train_df['Decision'].value_counts()\n",
    "print(\"📊 Distribution des résultats BAC:\")\n",
    "for decision, count in decision_counts.items():\n",
    "    percentage = (count / len(train_df)) * 100\n",
    "    print(f\"  {decision}: {count} étudiants ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Graphique en barres\n",
    "plt.subplot(1, 2, 1)\n",
    "decision_counts.plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "plt.title('Distribution des Résultats BAC 2022', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Décision')\n",
    "plt.ylabel('Nombre d\\'étudiants')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Graphique circulaire\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(decision_counts.values, labels=decision_counts.index, autopct='%1.1f%%',\n",
    "        colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "plt.title('Répartition des Résultats BAC', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 Insights:\")\n",
    "print(f\"- Le dataset est {'équilibré' if decision_counts.std() < decision_counts.mean() * 0.5 else 'déséquilibré'}\")\n",
    "print(f\"- Décision la plus fréquente: {decision_counts.index[0]} ({decision_counts.iloc[0]} étudiants)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyse des notes par matière\n",
    "print(\"📚 ANALYSE DES NOTES PAR MATIÈRE\")\n",
    "print()\n",
    "\n",
    "# Identifier les colonnes de notes (note1 à note8)\n",
    "note_columns = [col for col in train_df.columns if col.startswith('note')]\n",
    "print(f\"📝 Matières identifiées: {note_columns}\")\n",
    "\n",
    "# Statistiques des notes\n",
    "print(\"\\n📊 Statistiques des notes:\")\n",
    "notes_stats = train_df[note_columns].describe()\n",
    "print(notes_stats.round(2))\n",
    "\n",
    "# Visualisation de la distribution des notes\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Histogrammes des notes\n",
    "for i, note_col in enumerate(note_columns, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    plt.hist(train_df[note_col].dropna(), bins=20, alpha=0.7, color=f'C{i-1}')\n",
    "    plt.title(f'Distribution {note_col.upper()}')\n",
    "    plt.xlabel('Note')\n",
    "    plt.ylabel('Fréquence')\n",
    "    plt.axvline(train_df[note_col].mean(), color='red', linestyle='--', \n",
    "                label=f'Moyenne: {train_df[note_col].mean():.1f}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.suptitle('Distribution des Notes par Matière - BAC Mauritanie 2022', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Corrélation entre les notes et analyse géographique\n",
    "print(\"🗺️ ANALYSE GÉOGRAPHIQUE ET CORRÉLATIONS\")\n",
    "\n",
    "# Matrice de corrélation des notes\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = train_df[note_columns + ['moyeneGeneral']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, cbar_kws={'label': 'Corrélation'})\n",
    "plt.title('Matrice de Corrélation - Notes BAC 2022', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyse par Wilaya (région)\n",
    "print(\"\\n🏛️ Analyse par Wilaya:\")\n",
    "wilaya_success = train_df.groupby('Willaya')['Decision'].apply(\n",
    "    lambda x: (x == 'admis').sum() / len(x) * 100\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "wilaya_success.plot(kind='bar', color='skyblue')\n",
    "plt.title('Taux de Réussite par Wilaya - BAC 2022', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Wilaya')\n",
    "plt.ylabel('Taux de Réussite (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.axhline(y=wilaya_success.mean(), color='red', linestyle='--', \n",
    "            label=f'Moyenne nationale: {wilaya_success.mean():.1f}%')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"🏆 Meilleure Wilaya: {wilaya_success.index[0]} ({wilaya_success.iloc[0]:.1f}%)\")\n",
    "print(f\"📉 Wilaya à améliorer: {wilaya_success.index[-1]} ({wilaya_success.iloc[-1]:.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 🧹 ÉTAPE 2 : PRÉPARATION DES DONNÉES\n",
    "print(\"🧹 === PRÉPARATION DES DONNÉES ===\")\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "print(\"🔍 Analyse des valeurs manquantes:\")\n",
    "missing_data = train_df.isnull().sum()\n",
    "missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(missing_data)\n",
    "    \n",
    "    # Visualisation des valeurs manquantes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_data.plot(kind='bar', color='coral')\n",
    "    plt.title('Valeurs Manquantes par Colonne', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Colonnes')\n",
    "    plt.ylabel('Nombre de valeurs manquantes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"✅ Aucune valeur manquante détectée !\")\n",
    "\n",
    "# Créer une copie pour le preprocessing\n",
    "train_processed = train_df.copy()\n",
    "test_processed = test_df.copy()\n",
    "\n",
    "print(\"\\n📋 Datasets copiés pour le preprocessing\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature Engineering : créer de nouvelles variables\n",
    "print(\"⚗️ FEATURE ENGINEERING\")\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Créer de nouvelles caractéristiques pour améliorer notre modèle\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Moyenne des notes (si pas déjà présente)\n",
    "    note_cols = [col for col in df.columns if col.startswith('note')]\n",
    "    if 'moyenne_calculee' not in df.columns:\n",
    "        df['moyenne_calculee'] = df[note_cols].mean(axis=1)\n",
    "    \n",
    "    # 2. Écart-type des notes (régularité de l'étudiant)\n",
    "    df['regularite_notes'] = df[note_cols].std(axis=1)\n",
    "    \n",
    "    # 3. Note maximale et minimale\n",
    "    df['note_max'] = df[note_cols].max(axis=1)\n",
    "    df['note_min'] = df[note_cols].min(axis=1)\n",
    "    df['ecart_max_min'] = df['note_max'] - df['note_min']\n",
    "    \n",
    "    # 4. Nombre de matières réussies (note >= 10)\n",
    "    df['matieres_reussies'] = (df[note_cols] >= 10).sum(axis=1)\n",
    "    \n",
    "    # 5. Âge de l'étudiant (calculé à partir de la date de naissance)\n",
    "    if 'DateNaissance' in df.columns:\n",
    "        try:\n",
    "            df['DateNaissance'] = pd.to_datetime(df['DateNaissance'], errors='coerce')\n",
    "            exam_date = pd.to_datetime('2022-07-01')  # Date approximative de l'examen\n",
    "            df['age'] = (exam_date - df['DateNaissance']).dt.days / 365.25\n",
    "        except:\n",
    "            print(\"⚠️ Problème avec le calcul de l'âge\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appliquer le feature engineering\n",
    "train_processed = create_features(train_processed)\n",
    "test_processed = create_features(test_processed)\n",
    "\n",
    "print(\"✅ Nouvelles caractéristiques créées:\")\n",
    "new_features = ['moyenne_calculee', 'regularite_notes', 'note_max', 'note_min', \n",
    "                'ecart_max_min', 'matieres_reussies']\n",
    "for feature in new_features:\n",
    "    if feature in train_processed.columns:\n",
    "        print(f\"  ✓ {feature}\")\n",
    "\n",
    "# Statistiques des nouvelles features\n",
    "print(\"\\n📊 Statistiques des nouvelles caractéristiques:\")\n",
    "if 'regularite_notes' in train_processed.columns:\n",
    "    print(train_processed[new_features].describe().round(2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Encoding des variables catégorielles\n",
    "print(\"🏷️ ENCODING DES VARIABLES CATÉGORIELLES\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Identifier les colonnes catégorielles\n",
    "categorical_cols = train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'Decision' in categorical_cols:\n",
    "    categorical_cols.remove('Decision')  # Exclure la variable cible\n",
    "\n",
    "print(f\"📋 Variables catégorielles identifiées: {categorical_cols}\")\n",
    "\n",
    "# Label encoding pour les variables catégorielles\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in train_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        \n",
    "        # Combiner train et test pour l'encoding\n",
    "        combined_values = pd.concat([train_processed[col], test_processed[col]]).astype(str)\n",
    "        le.fit(combined_values)\n",
    "        \n",
    "        train_processed[f'{col}_encoded'] = le.transform(train_processed[col].astype(str))\n",
    "        test_processed[f'{col}_encoded'] = le.transform(test_processed[col].astype(str))\n",
    "        \n",
    "        label_encoders[col] = le\n",
    "        print(f\"  ✅ {col} encodé\")\n",
    "\n",
    "# Encoder la variable cible\n",
    "target_encoder = LabelEncoder()\n",
    "train_processed['Decision_encoded'] = target_encoder.fit_transform(train_processed['Decision'])\n",
    "\n",
    "print(f\"\\n🎯 Classes de la variable cible:\")\n",
    "for i, class_name in enumerate(target_encoder.classes_):\n",
    "    print(f\"  {i}: {class_name}\")\n",
    "\n",
    "print(\"\\n✅ Encoding terminé !\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 🤖 ÉTAPE 3 : MODÉLISATION MACHINE LEARNING\n",
    "print(\"🤖 === CONSTRUCTION DU MODÈLE ML ===\")\n",
    "\n",
    "# Sélection des features pour le modèle\n",
    "# Notes + nouvelles features + variables encodées\n",
    "note_columns = [col for col in train_processed.columns if col.startswith('note')]\n",
    "encoded_columns = [col for col in train_processed.columns if col.endswith('_encoded') and col != 'Decision_encoded']\n",
    "engineered_features = ['moyenne_calculee', 'regularite_notes', 'note_max', 'note_min', \n",
    "                      'ecart_max_min', 'matieres_reussies']\n",
    "\n",
    "# Autres features numériques importantes\n",
    "other_features = ['moyeneGeneral']\n",
    "if 'age' in train_processed.columns:\n",
    "    other_features.append('age')\n",
    "\n",
    "# Combiner toutes les features\n",
    "feature_columns = note_columns + engineered_features + encoded_columns + other_features\n",
    "feature_columns = [col for col in feature_columns if col in train_processed.columns]\n",
    "\n",
    "print(f\"📊 Features sélectionnées ({len(feature_columns)}):\")\n",
    "for col in feature_columns[:10]:  # Afficher les 10 premières\n",
    "    print(f\"  - {col}\")\n",
    "if len(feature_columns) > 10:\n",
    "    print(f\"  ... et {len(feature_columns) - 10} autres\")\n",
    "\n",
    "# Préparer les données pour l'entraînement\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['Decision_encoded']\n",
    "\n",
    "# Gérer les valeurs manquantes si nécessaire\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"\\n📐 Dimensions des données:\")\n",
    "print(f\"  X (features): {X.shape}\")\n",
    "print(f\"  y (target): {y.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Division en train/validation et entraînement des modèles\n",
    "print(\"🎯 ENTRAÎNEMENT DES MODÈLES\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Division train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"📊 Division des données:\")\n",
    "print(f\"  Training: {X_train.shape[0]} échantillons\")\n",
    "print(f\"  Validation: {X_val.shape[0]} échantillons\")\n",
    "\n",
    "# Initialiser différents modèles\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "}\n",
    "\n",
    "# Entraîner et évaluer chaque modèle\n",
    "model_results = {}\n",
    "\n",
    "print(\"\\n🏃‍♂️ Entraînement des modèles...\")\n",
    "for name, model in models.items():\n",
    "    print(f\"  📈 Entraînement {name}...\")\n",
    "    \n",
    "    # Entraînement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Évaluation\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"    ✓ Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"    ✓ CV Score: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "\n",
    "print(\"\\n✅ Tous les modèles entraînés !\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Comparaison et sélection du meilleur modèle\n",
    "print(\"🏆 === COMPARAISON DES MODÈLES ===\")\n",
    "\n",
    "# Créer un DataFrame de comparaison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(model_results.keys()),\n",
    "    'Validation_Accuracy': [results['accuracy'] for results in model_results.values()],\n",
    "    'CV_Mean': [results['cv_mean'] for results in model_results.values()],\n",
    "    'CV_Std': [results['cv_std'] for results in model_results.values()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Validation_Accuracy', ascending=False)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Visualisation de la comparaison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graphique des performances\n",
    "plt.subplot(1, 2, 1)\n",
    "x_pos = range(len(comparison_df))\n",
    "plt.bar(x_pos, comparison_df['Validation_Accuracy'], \n",
    "        color=['gold', 'silver', '#CD7F32', 'lightblue'][:len(comparison_df)])\n",
    "plt.xlabel('Modèles')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Performance des Modèles ML', fontweight='bold')\n",
    "plt.xticks(x_pos, comparison_df['Model'], rotation=45)\n",
    "\n",
    "# Sélectionner le meilleur modèle\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = model_results[best_model_name]['model']\n",
    "best_predictions = model_results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\n🥇 Meilleur modèle: {best_model_name}\")\n",
    "print(f\"   Accuracy: {comparison_df.iloc[0]['Validation_Accuracy']:.4f}\")\n",
    "\n",
    "# Matrice de confusion du meilleur modèle\n",
    "plt.subplot(1, 2, 2)\n",
    "cm = confusion_matrix(y_val, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_encoder.classes_,\n",
    "            yticklabels=target_encoder.classes_)\n",
    "plt.title(f'Matrice de Confusion\\n{best_model_name}', fontweight='bold')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Réalité')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rapport détaillé\n",
    "print(f\"\\n📋 Rapport de classification détaillé ({best_model_name}):\")\n",
    "print(classification_report(y_val, best_predictions, \n",
    "                          target_names=target_encoder.classes_))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature Importance (pour les modèles qui le supportent)\n",
    "print(\"📊 IMPORTANCE DES CARACTÉRISTIQUES\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Créer un DataFrame des importances\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_columns,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"🔝 Top 10 des caractéristiques les plus importantes:\")\n",
    "    print(importance_df.head(10).round(4))\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 15 - Importance des Caractéristiques\\n{best_model_name}', \n",
    "              fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n💡 Insights sur l'importance des features:\")\n",
    "    if 'moyeneGeneral' in importance_df.head(5)['Feature'].values:\n",
    "        print(\"   ✅ La moyenne générale est cruciale (comme attendu)\")\n",
    "    if any('note' in feat for feat in importance_df.head(5)['Feature'].values):\n",
    "        print(\"   ✅ Les notes individuelles sont importantes\")\n",
    "    if 'regularite_notes' in importance_df.head(10)['Feature'].values:\n",
    "        print(\"   ✅ La régularité des notes influence le résultat\")\nelse:\n",
    "    print(\"❌ Le modèle sélectionné ne supporte pas l'analyse d'importance des features\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 🚀 ÉTAPE 4 : PRÉDICTIONS ET SOUMISSION KAGGLE\n",
    "print(\"🚀 === GÉNÉRATION DES PRÉDICTIONS FINALES ===\")\n",
    "\n",
    "# Préparer les données de test\n",
    "X_test = test_processed[feature_columns]\n",
    "X_test = X_test.fillna(X_test.median())  # Gérer les valeurs manquantes\n",
    "\n",
    "print(f\"📊 Données de test préparées: {X_test.shape}\")\n",
    "\n",
    "# Entraîner le meilleur modèle sur toutes les données d'entraînement\n",
    "print(f\"🎯 Entraînement final du modèle {best_model_name} sur toutes les données...\")\n",
    "final_model = type(best_model)(**best_model.get_params())\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Prédictions sur le set de test\n",
    "test_predictions_encoded = final_model.predict(X_test)\n",
    "test_predictions = target_encoder.inverse_transform(test_predictions_encoded)\n",
    "\n",
    "print(\"✅ Prédictions générées !\")\n",
    "\n",
    "# Analyse des prédictions\n",
    "prediction_counts = pd.Series(test_predictions).value_counts()\n",
    "print(f\"\\n📊 Distribution des prédictions:\")\n",
    "for decision, count in prediction_counts.items():\n",
    "    percentage = (count / len(test_predictions)) * 100\n",
    "    print(f\"   {decision}: {count} étudiants ({percentage:.1f}%)\")\n",
    "\n",
    "# Créer le fichier de soumission\n",
    "submission = sample_submission.copy()\n",
    "\n",
    "# Vérifier les colonnes de soumission\n",
    "print(f\"\\n📋 Format de soumission attendu:\")\n",
    "print(f\"   Colonnes: {list(submission.columns)}\")\n",
    "print(f\"   Nombre de lignes: {len(submission)}\")\n",
    "\n",
    "# Assurer la correspondance des IDs\n",
    "if len(test_predictions) == len(submission):\n",
    "    # Supposer que la colonne de prédiction est la deuxième (après l'ID)\n",
    "    prediction_col = submission.columns[1]  \n",
    "    submission[prediction_col] = test_predictions\n",
    "    print(f\"✅ Prédictions assignées à la colonne '{prediction_col}'\")\nelse:\n",
    "    print(f\"❌ Erreur: Mismatch entre test predictions ({len(test_predictions)}) et submission ({len(submission)})\")\n",
    "\n",
    "# Sauvegarder le fichier de soumission\n",
    "submission_path = \"../../data/processed/bac_mauritanie_submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\n💾 Fichier de soumission sauvegardé: {submission_path}\")\n",
    "print(f\"📤 Prêt pour upload sur Kaggle !\")\n",
    "\n",
    "# Aperçu de la soumission\n",
    "print(f\"\\n👀 Aperçu de la soumission:\")\n",
    "print(submission.head(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 📈 RÉSUMÉ ET INSIGHTS FINAUX\n",
    "print(\"📈 === RÉSUMÉ DU PROJET BAC MAURITANIE 2022 ===\")\n",
    "print()\n",
    "\n",
    "print(\"🎯 OBJECTIF ATTEINT:\")\n",
    "print(f\"   ✅ Analyse complète du dataset BAC Mauritanie 2022\")\n",
    "print(f\"   ✅ Modèle ML entraîné avec {comparison_df.iloc[0]['Validation_Accuracy']:.1%} d'accuracy\")\n",
    "print(f\"   ✅ Prédictions générées pour {len(test_predictions)} étudiants\")\n",
    "print(f\"   ✅ Fichier de soumission Kaggle créé\")\n",
    "\n",
    "print(\"\\n🔍 INSIGHTS DÉCOUVERTS:\")\n",
    "print(f\"   📊 {len(train_df)} étudiants analysés\")\n",
    "print(f\"   🎓 Taux de réussite moyen: {(train_df['Decision'] == 'admis').mean():.1%}\")\n",
    "print(f\"   🏆 Meilleur modèle: {best_model_name}\")\n",
    "print(f\"   📍 {len(train_df['Willaya'].unique())} Wilayas représentées\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    top_feature = importance_df.iloc[0]['Feature']\n",
    "    print(f\"   🔝 Feature la plus importante: {top_feature}\")\n",
    "\n",
    "print(\"\\n🚀 WORKFLOW ML APPLIQUÉ:\")\n",
    "steps_completed = [\n",
    "    \"✅ 1. Définition du problème (Classification des résultats BAC)\",\n",
    "    \"✅ 2. Collecte des données (Dataset Kaggle)\", \n",
    "    \"✅ 3. Exploration des données (EDA complet)\",\n",
    "    \"✅ 4. Préparation des données (Cleaning + Feature Engineering)\",\n",
    "    \"✅ 5. Sélection de l'algorithme (Comparaison de 4 modèles)\",\n",
    "    \"✅ 6. Entraînement du modèle (Random Forest, etc.)\",\n",
    "    \"✅ 7. Évaluation du modèle (Cross-validation, métriques)\",\n",
    "    \"✅ 8. Déploiement (Fichier de soumission Kaggle)\"\n",
    "]\n",
    "\n",
    "for step in steps_completed:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\n🎓 COMPÉTENCES ML ACQUISES:\")\n",
    "skills = [\n",
    "    \"📊 Analyse exploratoire des données (EDA)\",\n",
    "    \"🧹 Preprocessing et nettoyage des données\", \n",
    "    \"⚗️ Feature Engineering (création de nouvelles variables)\",\n",
    "    \"🏷️ Encoding des variables catégorielles\",\n",
    "    \"🤖 Entraînement de modèles ML supervisés\",\n",
    "    \"📈 Évaluation et comparaison de modèles\",\n",
    "    \"🎯 Optimisation et sélection du meilleur modèle\",\n",
    "    \"📤 Préparation d'une soumission Kaggle\"\n",
    "]\n",
    "\n",
    "for skill in skills:\n",
    "    print(f\"   {skill}\")\n",
    "\n",
    "print(\"\\n🌟 PROCHAINES ÉTAPES:\")\n",
    "print(\"   🚀 Upload sur Kaggle et validation du score\")\n",
    "print(\"   📈 Session 2: Régression pour prédire les notes\")\n",
    "print(\"   🎯 Session 3: Classification avancée avec plus d'algorithmes\")\n",
    "print(\"   🔍 Session 4: Clustering pour segmenter les étudiants\")\n",
    "\n",
    "print(\"\\n🎉 FÉLICITATIONS ! Vous avez créé votre premier modèle ML complet ! 🎉\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 8. Récapitulatif et Réflexions\n",
    "\n",
    "### ✅ Ce que nous avons accompli aujourd'hui :\n",
    "\n",
    "- [x] **Théorie ML** : Définitions, types d'IA, familles ML, workflow\n",
    "- [x] **Projet Pratique** : Analyse complète du BAC Mauritanie 2022\n",
    "- [x] **EDA** : Exploration des données, visualisations, insights\n",
    "- [x] **Feature Engineering** : Création de nouvelles variables\n",
    "- [x] **Modélisation** : 4 algorithmes testés et comparés\n",
    "- [x] **Évaluation** : Métriques, validation croisée, sélection du meilleur modèle\n",
    "- [x] **Déploiement** : Fichier de soumission Kaggle prêt\n",
    "- [x] **Workflow ML complet** : De la définition du problème au déploiement\n",
    "\n",
    "### ❓ Questions de réflexion\n",
    "\n",
    "1. **Quel facteur influence le plus la réussite au BAC selon notre analyse ?**\n",
    "\n",
    "_Réponse :_ Selon l'analyse d'importance des features, la moyenne générale et la régularité des notes sont les facteurs les plus prédictifs.\n",
    "\n",
    "2. **Pourquoi avons-nous testé plusieurs modèles ML ?**\n",
    "\n",
    "_Réponse :_ Chaque algorithme a ses forces et faiblesses. La comparaison permet de choisir le plus adapté à notre problème spécifique.\n",
    "\n",
    "3. **Comment améliorer encore notre modèle ?**\n",
    "\n",
    "_Réponse :_ Hyperparameter tuning, feature selection avancée, ensemble methods, plus de données d'entraînement.\n",
    "\n",
    "### 💡 Insights Éducatifs Découverts :\n",
    "\n",
    "- Les disparités régionales sont réelles et mesurables\n",
    "- La régularité des notes est aussi importante que la moyenne\n",
    "- Certaines matières sont plus prédictives que d'autres\n",
    "- L'IA peut aider à identifier les étudiants à risque\n",
    "\n",
    "### 🚀 Applications Futures :\n",
    "\n",
    "Ce type d'analyse peut être utilisé pour :\n",
    "- **Système d'alerte précoce** : Identifier les étudiants à risque\n",
    "- **Optimisation pédagogique** : Adapter l'enseignement selon les besoins\n",
    "- **Politique éducative** : Cibler les régions nécessitant plus de ressources\n",
    "- **Orientation** : Conseiller les étudiants sur leurs forces/faiblesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📚 Ressources pour aller plus loin\n",
    "\n",
    "### 📖 Lectures recommandées :\n",
    "- [Cours CS229 de Stanford](https://cs229.stanford.edu/)\n",
    "- [Introduction to Statistical Learning](https://www.statlearning.com/)\n",
    "- [Kaggle Learn - Machine Learning](https://www.kaggle.com/learn/machine-learning)\n",
    "\n",
    "### 🎥 Vidéos :\n",
    "- [3Blue1Brown - Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "- [Andrew Ng - Machine Learning Course](https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "### 🏗️ Prochaine session :\n",
    "**Session 2 - Régression et Prédiction**\n",
    "- Régression linéaire et polynomiale\n",
    "- Métriques d'évaluation (RMSE, MAE, R²)\n",
    "- Cas pratique : prédiction des notes individuelles\n",
    "- Régularisation (Ridge, Lasso)\n",
    "\n",
    "### 🏆 Défi pour la maison :\n",
    "1. **Uploadez votre soumission sur Kaggle** et partagez votre score !\n",
    "2. **Essayez d'améliorer le modèle** en créant de nouvelles features\n",
    "3. **Analysez les erreurs** : quels étudiants sont mal classifiés et pourquoi ?\n",
    "4. **Explorez d'autres algorithmes** : SVM, XGBoost, Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "**📧 Contact :** mohamed.beydia@vela-learning.com  \n",
    "**🌐 Vela Learning :** [https://vela-learning.com](https://vela-learning.com)  \n",
    "**🎓 SupNum Nouakchott**\n",
    "\n",
    "**🎉 Bravo pour votre première réalisation en Machine Learning ! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
