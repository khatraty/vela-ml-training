{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ Session 1 - Introduction Ã  l'IA et au Machine Learning\n",
    "## Solutions avec Cas Pratique : PrÃ©diction BAC Mauritanie 2022\n",
    "\n",
    "**Formation IA & ML - SupNum Nouakchott**  \n",
    "**Formateur:** Mohamed Beydia - Vela Learning  \n",
    "**Dataset:** BAC Mauritanie 2022 Predictive Modeling Challenge\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Objectifs de la session\n",
    "\n",
    "Ã€ la fin de cette session, vous serez capables de :\n",
    "- [x] DÃ©finir l'Intelligence Artificielle, le Machine Learning et le Deep Learning\n",
    "- [x] Distinguer l'IA symbolique de l'IA statistique\n",
    "- [x] Comprendre la diffÃ©rence entre IA analytique et gÃ©nÃ©rative\n",
    "- [x] Identifier les trois familles principales du ML\n",
    "- [x] DÃ©crire le workflow standard d'un projet ML\n",
    "- [x] ReconnaÃ®tre des cas d'usage concrets d'IA\n",
    "- [x] **BONUS:** Analyser un dataset rÃ©el et crÃ©er votre premiÃ¨re prÃ©diction ML !\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– 1. Qu'est-ce que l'Intelligence Artificielle ?\n",
    "\n",
    "### ğŸ“ Solutions - DÃ©finitions\n",
    "\n",
    "**Intelligence Artificielle (IA)** : CapacitÃ© d'une machine Ã  imiter l'intelligence humaine pour rÃ©soudre des problÃ¨mes, prendre des dÃ©cisions et s'adapter Ã  de nouvelles situations.\n",
    "\n",
    "**Machine Learning (ML)** : Sous-domaine de l'IA qui permet aux machines d'apprendre automatiquement Ã  partir de donnÃ©es sans Ãªtre explicitement programmÃ©es pour chaque tÃ¢che.\n",
    "\n",
    "**Deep Learning (DL)** : Sous-domaine du ML utilisant des rÃ©seaux de neurones artificiels profonds (multiples couches) pour rÃ©soudre des problÃ¨mes complexes.\n",
    "\n",
    "### ğŸ”— Relation hiÃ©rarchique :\n",
    "**IA âŠƒ ML âŠƒ Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 2. Types d'Intelligence Artificielle\n",
    "\n",
    "### ğŸ“ Solutions - IA Symbolique vs IA Statistique\n",
    "\n",
    "1. Un systÃ¨me expert mÃ©dical avec des rÃ¨gles if-then â†’ **IA Symbolique**\n",
    "2. Un modÃ¨le de reconnaissance d'images â†’ **IA Statistique**\n",
    "3. Un chatbot basÃ© sur des arbres de dÃ©cision â†’ **IA Symbolique**\n",
    "4. Un algorithme de recommandation Netflix â†’ **IA Statistique**\n",
    "5. Un systÃ¨me de diagnostic automatique â†’ **IA Statistique** (gÃ©nÃ©ralement)\n",
    "\n",
    "**Notre cas BAC Mauritanie** : IA Statistique - nous allons utiliser des donnÃ©es pour prÃ©dire les rÃ©sultats !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ 3. IA Analytique vs IA GÃ©nÃ©rative\n",
    "\n",
    "### ğŸ“ Solutions - Classification des applications\n",
    "\n",
    "| Application | Type IA | Justification |\n",
    "|-------------|---------|---------------|\n",
    "| ChatGPT | **GÃ©nÃ©rative** | CrÃ©e du nouveau contenu textuel |\n",
    "| DÃ©tection de spam | **Analytique** | Analyse et classifie des emails existants |\n",
    "| DALL-E | **GÃ©nÃ©rative** | GÃ©nÃ¨re de nouvelles images |\n",
    "| PrÃ©diction de ventes | **Analytique** | Analyse les donnÃ©es historiques |\n",
    "| GitHub Copilot | **GÃ©nÃ©rative** | GÃ©nÃ¨re du code |\n",
    "| Analyse de sentiments | **Analytique** | Classifie les Ã©motions dans le texte |\n",
    "\n",
    "**Notre projet BAC** : IA Analytique - nous analysons les donnÃ©es pour prÃ©dire les rÃ©sultats des Ã©tudiants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 4. Les Familles du Machine Learning\n",
    "\n",
    "### ğŸ“ Solutions - Familles ML\n",
    "\n",
    "| Famille ML | DÃ©finition | Exemple d'algorithme | Cas d'usage |\n",
    "|------------|------------|---------------------|-------------|\n",
    "| **SupervisÃ©** | Apprentissage avec donnÃ©es Ã©tiquetÃ©es | RÃ©gression linÃ©aire, Random Forest | PrÃ©diction BAC, dÃ©tection spam |\n",
    "| **Non supervisÃ©** | Apprentissage sans Ã©tiquettes | K-means, PCA | Segmentation clients, compression |\n",
    "| **Par renforcement** | Apprentissage par rÃ©compenses/punitions | Q-learning, Policy Gradient | Jeux, robotique, trading |\n",
    "\n",
    "**Notre projet BAC utilisera l'apprentissage supervisÃ©** car nous avons les notes (Ã©tiquettes) pour prÃ©dire les rÃ©sultats futurs !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ 5. Workflow Machine Learning\n",
    "\n",
    "### ğŸ“ Solutions - Workflow ML\n",
    "\n",
    "**Ordre correct :**\n",
    "1. **DÃ©finition du problÃ¨me** - Que voulons-nous prÃ©dire ?\n",
    "2. **Collecte des donnÃ©es** - Rassembler les donnÃ©es BAC\n",
    "3. **PrÃ©paration des donnÃ©es** - Nettoyage, transformation\n",
    "4. **SÃ©lection de l'algorithme** - Choisir le bon modÃ¨le ML\n",
    "5. **EntraÃ®nement du modÃ¨le** - Apprendre des donnÃ©es\n",
    "6. **Ã‰valuation du modÃ¨le** - Mesurer la performance\n",
    "7. **DÃ©ploiement** - Mise en production\n",
    "8. **Monitoring et maintenance** - Surveillance continue\n",
    "\n",
    "**Nous allons suivre ce workflow pour le dataset BAC !** ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ 6. Cas d'Usage de l'IA\n",
    "\n",
    "### ğŸ“ Solutions - Cas d'usage par secteur\n",
    "\n",
    "#### ğŸ“ Ã‰ducation\n",
    "- **PrÃ©diction de rÃ©ussite scolaire** (notre cas !)\n",
    "- Personnalisation des parcours d'apprentissage\n",
    "- DÃ©tection prÃ©coce du dÃ©crochage scolaire\n",
    "- Correction automatique et feedback intelligent\n",
    "\n",
    "#### ğŸ’¼ Business/Finance\n",
    "- DÃ©tection de fraude bancaire\n",
    "- Analyse des risques de crÃ©dit\n",
    "- Trading algorithmique\n",
    "- Optimisation des prix dynamiques\n",
    "\n",
    "#### ğŸ¥ SantÃ©\n",
    "- Diagnostic mÃ©dical assistÃ© par IA\n",
    "- DÃ©couverte de mÃ©dicaments\n",
    "- Analyse d'imagerie mÃ©dicale\n",
    "- PrÃ©diction d'Ã©pidÃ©mies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’» 7. PROJET PRATIQUE : Analyse BAC Mauritanie 2022\n",
    "\n",
    "### ğŸ¯ Notre DÃ©fi Kaggle\n",
    "**Objectif :** PrÃ©dire les rÃ©sultats du BAC 2022 en Mauritanie Ã  partir des donnÃ©es des candidats\n",
    "\n",
    "**Type de problÃ¨me :** Classification supervisÃ©e  \n",
    "**MÃ©trique :** Accuracy, Precision, Recall\n",
    "\n",
    "CommenÃ§ons par explorer nos donnÃ©es !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import des librairies essentielles pour notre projet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour les graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Librairies importÃ©es avec succÃ¨s !\")\n",
    "print(f\"ğŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy version: {np.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extraction et chargement des donnÃ©es BAC Mauritanie\n",
    "import os\n",
    "\n",
    "# Chemin vers le fichier zip\n",
    "zip_path = \"../../data/external/bac-mauritanie-2022-predictive-modeling-challeng.zip\"\n",
    "extract_path = \"../../data/raw/bac_mauritanie/\"\n",
    "\n",
    "# CrÃ©er le dossier d'extraction s'il n'existe pas\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extraire les donnÃ©es\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"âœ… DonnÃ©es extraites avec succÃ¨s !\")\n",
    "    \n",
    "    # Lister les fichiers extraits\n",
    "    files = os.listdir(extract_path)\n",
    "    print(\"ğŸ“ Fichiers disponibles:\")\n",
    "    for file in files:\n",
    "        print(f\"  - {file}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors de l'extraction: {e}\")\n",
    "    print(\"VÃ©rifiez que le fichier zip existe dans data/external/\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Chargement des datasets\n",
    "try:\n",
    "    # Chargement des donnÃ©es d'entraÃ®nement et de test\n",
    "    train_df = pd.read_csv(f\"{extract_path}/train.csv\")\n",
    "    test_df = pd.read_csv(f\"{extract_path}/test.csv\")\n",
    "    sample_submission = pd.read_csv(f\"{extract_path}/sample_template.csv\")\n",
    "    \n",
    "    print(\"âœ… Datasets chargÃ©s avec succÃ¨s !\")\n",
    "    print(f\"ğŸ“Š DonnÃ©es d'entraÃ®nement: {train_df.shape[0]} lignes, {train_df.shape[1]} colonnes\")\n",
    "    print(f\"ğŸ“Š DonnÃ©es de test: {test_df.shape[0]} lignes, {test_df.shape[1]} colonnes\")\n",
    "    print(f\"ğŸ“Š Template de soumission: {sample_submission.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors du chargement: {e}\")\n",
    "    print(\"Les fichiers CSV doivent Ãªtre extraits dans le dossier raw/bac_mauritanie/\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ” Ã‰TAPE 1 : EXPLORATION DES DONNÃ‰ES (EDA)\n",
    "print(\"ğŸ” === EXPLORATION DES DONNÃ‰ES BAC MAURITANIE 2022 ===\")\n",
    "print()\n",
    "\n",
    "# AperÃ§u des donnÃ©es d'entraÃ®nement\n",
    "print(\"ğŸ“‹ AperÃ§u des donnÃ©es d'entraÃ®nement:\")\n",
    "print(train_df.head())\n",
    "print()\n",
    "\n",
    "# Informations sur les colonnes\n",
    "print(\"ğŸ“Š Informations sur les colonnes:\")\n",
    "print(train_df.info())\n",
    "print()\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"ğŸ“ˆ Statistiques descriptives:\")\n",
    "print(train_df.describe())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyse de la variable cible (Decision)\n",
    "print(\"ğŸ¯ ANALYSE DE LA VARIABLE CIBLE : 'Decision'\")\n",
    "print()\n",
    "\n",
    "# Distribution de la variable cible\n",
    "decision_counts = train_df['Decision'].value_counts()\n",
    "print(\"ğŸ“Š Distribution des rÃ©sultats BAC:\")\n",
    "for decision, count in decision_counts.items():\n",
    "    percentage = (count / len(train_df)) * 100\n",
    "    print(f\"  {decision}: {count} Ã©tudiants ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Graphique en barres\n",
    "plt.subplot(1, 2, 1)\n",
    "decision_counts.plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "plt.title('Distribution des RÃ©sultats BAC 2022', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('DÃ©cision')\n",
    "plt.ylabel('Nombre d\\'Ã©tudiants')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Graphique circulaire\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(decision_counts.values, labels=decision_counts.index, autopct='%1.1f%%',\n",
    "        colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "plt.title('RÃ©partition des RÃ©sultats BAC', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Insights:\")\n",
    "print(f\"- Le dataset est {'Ã©quilibrÃ©' if decision_counts.std() < decision_counts.mean() * 0.5 else 'dÃ©sÃ©quilibrÃ©'}\")\n",
    "print(f\"- DÃ©cision la plus frÃ©quente: {decision_counts.index[0]} ({decision_counts.iloc[0]} Ã©tudiants)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyse des notes par matiÃ¨re\n",
    "print(\"ğŸ“š ANALYSE DES NOTES PAR MATIÃˆRE\")\n",
    "print()\n",
    "\n",
    "# Identifier les colonnes de notes (note1 Ã  note8)\n",
    "note_columns = [col for col in train_df.columns if col.startswith('note')]\n",
    "print(f\"ğŸ“ MatiÃ¨res identifiÃ©es: {note_columns}\")\n",
    "\n",
    "# Statistiques des notes\n",
    "print(\"\\nğŸ“Š Statistiques des notes:\")\n",
    "notes_stats = train_df[note_columns].describe()\n",
    "print(notes_stats.round(2))\n",
    "\n",
    "# Visualisation de la distribution des notes\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Histogrammes des notes\n",
    "for i, note_col in enumerate(note_columns, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    plt.hist(train_df[note_col].dropna(), bins=20, alpha=0.7, color=f'C{i-1}')\n",
    "    plt.title(f'Distribution {note_col.upper()}')\n",
    "    plt.xlabel('Note')\n",
    "    plt.ylabel('FrÃ©quence')\n",
    "    plt.axvline(train_df[note_col].mean(), color='red', linestyle='--', \n",
    "                label=f'Moyenne: {train_df[note_col].mean():.1f}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.suptitle('Distribution des Notes par MatiÃ¨re - BAC Mauritanie 2022', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CorrÃ©lation entre les notes et analyse gÃ©ographique\n",
    "print(\"ğŸ—ºï¸ ANALYSE GÃ‰OGRAPHIQUE ET CORRÃ‰LATIONS\")\n",
    "\n",
    "# Matrice de corrÃ©lation des notes\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = train_df[note_columns + ['moyeneGeneral']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, cbar_kws={'label': 'CorrÃ©lation'})\n",
    "plt.title('Matrice de CorrÃ©lation - Notes BAC 2022', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyse par Wilaya (rÃ©gion)\n",
    "print(\"\\nğŸ›ï¸ Analyse par Wilaya:\")\n",
    "wilaya_success = train_df.groupby('Willaya')['Decision'].apply(\n",
    "    lambda x: (x == 'admis').sum() / len(x) * 100\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "wilaya_success.plot(kind='bar', color='skyblue')\n",
    "plt.title('Taux de RÃ©ussite par Wilaya - BAC 2022', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Wilaya')\n",
    "plt.ylabel('Taux de RÃ©ussite (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.axhline(y=wilaya_success.mean(), color='red', linestyle='--', \n",
    "            label=f'Moyenne nationale: {wilaya_success.mean():.1f}%')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ† Meilleure Wilaya: {wilaya_success.index[0]} ({wilaya_success.iloc[0]:.1f}%)\")\n",
    "print(f\"ğŸ“‰ Wilaya Ã  amÃ©liorer: {wilaya_success.index[-1]} ({wilaya_success.iloc[-1]:.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ§¹ Ã‰TAPE 2 : PRÃ‰PARATION DES DONNÃ‰ES\n",
    "print(\"ğŸ§¹ === PRÃ‰PARATION DES DONNÃ‰ES ===\")\n",
    "\n",
    "# VÃ©rifier les valeurs manquantes\n",
    "print(\"ğŸ” Analyse des valeurs manquantes:\")\n",
    "missing_data = train_df.isnull().sum()\n",
    "missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(missing_data)\n",
    "    \n",
    "    # Visualisation des valeurs manquantes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_data.plot(kind='bar', color='coral')\n",
    "    plt.title('Valeurs Manquantes par Colonne', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Colonnes')\n",
    "    plt.ylabel('Nombre de valeurs manquantes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"âœ… Aucune valeur manquante dÃ©tectÃ©e !\")\n",
    "\n",
    "# CrÃ©er une copie pour le preprocessing\n",
    "train_processed = train_df.copy()\n",
    "test_processed = test_df.copy()\n",
    "\n",
    "print(\"\\nğŸ“‹ Datasets copiÃ©s pour le preprocessing\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature Engineering : crÃ©er de nouvelles variables\n",
    "print(\"âš—ï¸ FEATURE ENGINEERING\")\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"CrÃ©er de nouvelles caractÃ©ristiques pour amÃ©liorer notre modÃ¨le\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Moyenne des notes (si pas dÃ©jÃ  prÃ©sente)\n",
    "    note_cols = [col for col in df.columns if col.startswith('note')]\n",
    "    if 'moyenne_calculee' not in df.columns:\n",
    "        df['moyenne_calculee'] = df[note_cols].mean(axis=1)\n",
    "    \n",
    "    # 2. Ã‰cart-type des notes (rÃ©gularitÃ© de l'Ã©tudiant)\n",
    "    df['regularite_notes'] = df[note_cols].std(axis=1)\n",
    "    \n",
    "    # 3. Note maximale et minimale\n",
    "    df['note_max'] = df[note_cols].max(axis=1)\n",
    "    df['note_min'] = df[note_cols].min(axis=1)\n",
    "    df['ecart_max_min'] = df['note_max'] - df['note_min']\n",
    "    \n",
    "    # 4. Nombre de matiÃ¨res rÃ©ussies (note >= 10)\n",
    "    df['matieres_reussies'] = (df[note_cols] >= 10).sum(axis=1)\n",
    "    \n",
    "    # 5. Ã‚ge de l'Ã©tudiant (calculÃ© Ã  partir de la date de naissance)\n",
    "    if 'DateNaissance' in df.columns:\n",
    "        try:\n",
    "            df['DateNaissance'] = pd.to_datetime(df['DateNaissance'], errors='coerce')\n",
    "            exam_date = pd.to_datetime('2022-07-01')  # Date approximative de l'examen\n",
    "            df['age'] = (exam_date - df['DateNaissance']).dt.days / 365.25\n",
    "        except:\n",
    "            print(\"âš ï¸ ProblÃ¨me avec le calcul de l'Ã¢ge\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appliquer le feature engineering\n",
    "train_processed = create_features(train_processed)\n",
    "test_processed = create_features(test_processed)\n",
    "\n",
    "print(\"âœ… Nouvelles caractÃ©ristiques crÃ©Ã©es:\")\n",
    "new_features = ['moyenne_calculee', 'regularite_notes', 'note_max', 'note_min', \n",
    "                'ecart_max_min', 'matieres_reussies']\n",
    "for feature in new_features:\n",
    "    if feature in train_processed.columns:\n",
    "        print(f\"  âœ“ {feature}\")\n",
    "\n",
    "# Statistiques des nouvelles features\n",
    "print(\"\\nğŸ“Š Statistiques des nouvelles caractÃ©ristiques:\")\n",
    "if 'regularite_notes' in train_processed.columns:\n",
    "    print(train_processed[new_features].describe().round(2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Encoding des variables catÃ©gorielles\n",
    "print(\"ğŸ·ï¸ ENCODING DES VARIABLES CATÃ‰GORIELLES\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Identifier les colonnes catÃ©gorielles\n",
    "categorical_cols = train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'Decision' in categorical_cols:\n",
    "    categorical_cols.remove('Decision')  # Exclure la variable cible\n",
    "\n",
    "print(f\"ğŸ“‹ Variables catÃ©gorielles identifiÃ©es: {categorical_cols}\")\n",
    "\n",
    "# Label encoding pour les variables catÃ©gorielles\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in train_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        \n",
    "        # Combiner train et test pour l'encoding\n",
    "        combined_values = pd.concat([train_processed[col], test_processed[col]]).astype(str)\n",
    "        le.fit(combined_values)\n",
    "        \n",
    "        train_processed[f'{col}_encoded'] = le.transform(train_processed[col].astype(str))\n",
    "        test_processed[f'{col}_encoded'] = le.transform(test_processed[col].astype(str))\n",
    "        \n",
    "        label_encoders[col] = le\n",
    "        print(f\"  âœ… {col} encodÃ©\")\n",
    "\n",
    "# Encoder la variable cible\n",
    "target_encoder = LabelEncoder()\n",
    "train_processed['Decision_encoded'] = target_encoder.fit_transform(train_processed['Decision'])\n",
    "\n",
    "print(f\"\\nğŸ¯ Classes de la variable cible:\")\n",
    "for i, class_name in enumerate(target_encoder.classes_):\n",
    "    print(f\"  {i}: {class_name}\")\n",
    "\n",
    "print(\"\\nâœ… Encoding terminÃ© !\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ¤– Ã‰TAPE 3 : MODÃ‰LISATION MACHINE LEARNING\n",
    "print(\"ğŸ¤– === CONSTRUCTION DU MODÃˆLE ML ===\")\n",
    "\n",
    "# SÃ©lection des features pour le modÃ¨le\n",
    "# Notes + nouvelles features + variables encodÃ©es\n",
    "note_columns = [col for col in train_processed.columns if col.startswith('note')]\n",
    "encoded_columns = [col for col in train_processed.columns if col.endswith('_encoded') and col != 'Decision_encoded']\n",
    "engineered_features = ['moyenne_calculee', 'regularite_notes', 'note_max', 'note_min', \n",
    "                      'ecart_max_min', 'matieres_reussies']\n",
    "\n",
    "# Autres features numÃ©riques importantes\n",
    "other_features = ['moyeneGeneral']\n",
    "if 'age' in train_processed.columns:\n",
    "    other_features.append('age')\n",
    "\n",
    "# Combiner toutes les features\n",
    "feature_columns = note_columns + engineered_features + encoded_columns + other_features\n",
    "feature_columns = [col for col in feature_columns if col in train_processed.columns]\n",
    "\n",
    "print(f\"ğŸ“Š Features sÃ©lectionnÃ©es ({len(feature_columns)}):\")\n",
    "for col in feature_columns[:10]:  # Afficher les 10 premiÃ¨res\n",
    "    print(f\"  - {col}\")\n",
    "if len(feature_columns) > 10:\n",
    "    print(f\"  ... et {len(feature_columns) - 10} autres\")\n",
    "\n",
    "# PrÃ©parer les donnÃ©es pour l'entraÃ®nement\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['Decision_encoded']\n",
    "\n",
    "# GÃ©rer les valeurs manquantes si nÃ©cessaire\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"\\nğŸ“ Dimensions des donnÃ©es:\")\n",
    "print(f\"  X (features): {X.shape}\")\n",
    "print(f\"  y (target): {y.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Division en train/validation et entraÃ®nement des modÃ¨les\n",
    "print(\"ğŸ¯ ENTRAÃNEMENT DES MODÃˆLES\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Division train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"ğŸ“Š Division des donnÃ©es:\")\n",
    "print(f\"  Training: {X_train.shape[0]} Ã©chantillons\")\n",
    "print(f\"  Validation: {X_val.shape[0]} Ã©chantillons\")\n",
    "\n",
    "# Initialiser diffÃ©rents modÃ¨les\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "}\n",
    "\n",
    "# EntraÃ®ner et Ã©valuer chaque modÃ¨le\n",
    "model_results = {}\n",
    "\n",
    "print(\"\\nğŸƒâ€â™‚ï¸ EntraÃ®nement des modÃ¨les...\")\n",
    "for name, model in models.items():\n",
    "    print(f\"  ğŸ“ˆ EntraÃ®nement {name}...\")\n",
    "    \n",
    "    # EntraÃ®nement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # PrÃ©dictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Ã‰valuation\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"    âœ“ Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"    âœ“ CV Score: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})\")\n",
    "\n",
    "print(\"\\nâœ… Tous les modÃ¨les entraÃ®nÃ©s !\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Comparaison et sÃ©lection du meilleur modÃ¨le\n",
    "print(\"ğŸ† === COMPARAISON DES MODÃˆLES ===\")\n",
    "\n",
    "# CrÃ©er un DataFrame de comparaison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(model_results.keys()),\n",
    "    'Validation_Accuracy': [results['accuracy'] for results in model_results.values()],\n",
    "    'CV_Mean': [results['cv_mean'] for results in model_results.values()],\n",
    "    'CV_Std': [results['cv_std'] for results in model_results.values()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Validation_Accuracy', ascending=False)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Visualisation de la comparaison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graphique des performances\n",
    "plt.subplot(1, 2, 1)\n",
    "x_pos = range(len(comparison_df))\n",
    "plt.bar(x_pos, comparison_df['Validation_Accuracy'], \n",
    "        color=['gold', 'silver', '#CD7F32', 'lightblue'][:len(comparison_df)])\n",
    "plt.xlabel('ModÃ¨les')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Performance des ModÃ¨les ML', fontweight='bold')\n",
    "plt.xticks(x_pos, comparison_df['Model'], rotation=45)\n",
    "\n",
    "# SÃ©lectionner le meilleur modÃ¨le\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = model_results[best_model_name]['model']\n",
    "best_predictions = model_results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\nğŸ¥‡ Meilleur modÃ¨le: {best_model_name}\")\n",
    "print(f\"   Accuracy: {comparison_df.iloc[0]['Validation_Accuracy']:.4f}\")\n",
    "\n",
    "# Matrice de confusion du meilleur modÃ¨le\n",
    "plt.subplot(1, 2, 2)\n",
    "cm = confusion_matrix(y_val, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_encoder.classes_,\n",
    "            yticklabels=target_encoder.classes_)\n",
    "plt.title(f'Matrice de Confusion\\n{best_model_name}', fontweight='bold')\n",
    "plt.xlabel('PrÃ©dictions')\n",
    "plt.ylabel('RÃ©alitÃ©')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rapport dÃ©taillÃ©\n",
    "print(f\"\\nğŸ“‹ Rapport de classification dÃ©taillÃ© ({best_model_name}):\")\n",
    "print(classification_report(y_val, best_predictions, \n",
    "                          target_names=target_encoder.classes_))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature Importance (pour les modÃ¨les qui le supportent)\n",
    "print(\"ğŸ“Š IMPORTANCE DES CARACTÃ‰RISTIQUES\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # CrÃ©er un DataFrame des importances\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_columns,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"ğŸ” Top 10 des caractÃ©ristiques les plus importantes:\")\n",
    "    print(importance_df.head(10).round(4))\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 15 - Importance des CaractÃ©ristiques\\n{best_model_name}', \n",
    "              fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nğŸ’¡ Insights sur l'importance des features:\")\n",
    "    if 'moyeneGeneral' in importance_df.head(5)['Feature'].values:\n",
    "        print(\"   âœ… La moyenne gÃ©nÃ©rale est cruciale (comme attendu)\")\n",
    "    if any('note' in feat for feat in importance_df.head(5)['Feature'].values):\n",
    "        print(\"   âœ… Les notes individuelles sont importantes\")\n",
    "    if 'regularite_notes' in importance_df.head(10)['Feature'].values:\n",
    "        print(\"   âœ… La rÃ©gularitÃ© des notes influence le rÃ©sultat\")\nelse:\n",
    "    print(\"âŒ Le modÃ¨le sÃ©lectionnÃ© ne supporte pas l'analyse d'importance des features\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸš€ Ã‰TAPE 4 : PRÃ‰DICTIONS ET SOUMISSION KAGGLE\n",
    "print(\"ğŸš€ === GÃ‰NÃ‰RATION DES PRÃ‰DICTIONS FINALES ===\")\n",
    "\n",
    "# PrÃ©parer les donnÃ©es de test\n",
    "X_test = test_processed[feature_columns]\n",
    "X_test = X_test.fillna(X_test.median())  # GÃ©rer les valeurs manquantes\n",
    "\n",
    "print(f\"ğŸ“Š DonnÃ©es de test prÃ©parÃ©es: {X_test.shape}\")\n",
    "\n",
    "# EntraÃ®ner le meilleur modÃ¨le sur toutes les donnÃ©es d'entraÃ®nement\n",
    "print(f\"ğŸ¯ EntraÃ®nement final du modÃ¨le {best_model_name} sur toutes les donnÃ©es...\")\n",
    "final_model = type(best_model)(**best_model.get_params())\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# PrÃ©dictions sur le set de test\n",
    "test_predictions_encoded = final_model.predict(X_test)\n",
    "test_predictions = target_encoder.inverse_transform(test_predictions_encoded)\n",
    "\n",
    "print(\"âœ… PrÃ©dictions gÃ©nÃ©rÃ©es !\")\n",
    "\n",
    "# Analyse des prÃ©dictions\n",
    "prediction_counts = pd.Series(test_predictions).value_counts()\n",
    "print(f\"\\nğŸ“Š Distribution des prÃ©dictions:\")\n",
    "for decision, count in prediction_counts.items():\n",
    "    percentage = (count / len(test_predictions)) * 100\n",
    "    print(f\"   {decision}: {count} Ã©tudiants ({percentage:.1f}%)\")\n",
    "\n",
    "# CrÃ©er le fichier de soumission\n",
    "submission = sample_submission.copy()\n",
    "\n",
    "# VÃ©rifier les colonnes de soumission\n",
    "print(f\"\\nğŸ“‹ Format de soumission attendu:\")\n",
    "print(f\"   Colonnes: {list(submission.columns)}\")\n",
    "print(f\"   Nombre de lignes: {len(submission)}\")\n",
    "\n",
    "# Assurer la correspondance des IDs\n",
    "if len(test_predictions) == len(submission):\n",
    "    # Supposer que la colonne de prÃ©diction est la deuxiÃ¨me (aprÃ¨s l'ID)\n",
    "    prediction_col = submission.columns[1]  \n",
    "    submission[prediction_col] = test_predictions\n",
    "    print(f\"âœ… PrÃ©dictions assignÃ©es Ã  la colonne '{prediction_col}'\")\nelse:\n",
    "    print(f\"âŒ Erreur: Mismatch entre test predictions ({len(test_predictions)}) et submission ({len(submission)})\")\n",
    "\n",
    "# Sauvegarder le fichier de soumission\n",
    "submission_path = \"../../data/processed/bac_mauritanie_submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Fichier de soumission sauvegardÃ©: {submission_path}\")\n",
    "print(f\"ğŸ“¤ PrÃªt pour upload sur Kaggle !\")\n",
    "\n",
    "# AperÃ§u de la soumission\n",
    "print(f\"\\nğŸ‘€ AperÃ§u de la soumission:\")\n",
    "print(submission.head(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ“ˆ RÃ‰SUMÃ‰ ET INSIGHTS FINAUX\n",
    "print(\"ğŸ“ˆ === RÃ‰SUMÃ‰ DU PROJET BAC MAURITANIE 2022 ===\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ¯ OBJECTIF ATTEINT:\")\n",
    "print(f\"   âœ… Analyse complÃ¨te du dataset BAC Mauritanie 2022\")\n",
    "print(f\"   âœ… ModÃ¨le ML entraÃ®nÃ© avec {comparison_df.iloc[0]['Validation_Accuracy']:.1%} d'accuracy\")\n",
    "print(f\"   âœ… PrÃ©dictions gÃ©nÃ©rÃ©es pour {len(test_predictions)} Ã©tudiants\")\n",
    "print(f\"   âœ… Fichier de soumission Kaggle crÃ©Ã©\")\n",
    "\n",
    "print(\"\\nğŸ” INSIGHTS DÃ‰COUVERTS:\")\n",
    "print(f\"   ğŸ“Š {len(train_df)} Ã©tudiants analysÃ©s\")\n",
    "print(f\"   ğŸ“ Taux de rÃ©ussite moyen: {(train_df['Decision'] == 'admis').mean():.1%}\")\n",
    "print(f\"   ğŸ† Meilleur modÃ¨le: {best_model_name}\")\n",
    "print(f\"   ğŸ“ {len(train_df['Willaya'].unique())} Wilayas reprÃ©sentÃ©es\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    top_feature = importance_df.iloc[0]['Feature']\n",
    "    print(f\"   ğŸ” Feature la plus importante: {top_feature}\")\n",
    "\n",
    "print(\"\\nğŸš€ WORKFLOW ML APPLIQUÃ‰:\")\n",
    "steps_completed = [\n",
    "    \"âœ… 1. DÃ©finition du problÃ¨me (Classification des rÃ©sultats BAC)\",\n",
    "    \"âœ… 2. Collecte des donnÃ©es (Dataset Kaggle)\", \n",
    "    \"âœ… 3. Exploration des donnÃ©es (EDA complet)\",\n",
    "    \"âœ… 4. PrÃ©paration des donnÃ©es (Cleaning + Feature Engineering)\",\n",
    "    \"âœ… 5. SÃ©lection de l'algorithme (Comparaison de 4 modÃ¨les)\",\n",
    "    \"âœ… 6. EntraÃ®nement du modÃ¨le (Random Forest, etc.)\",\n",
    "    \"âœ… 7. Ã‰valuation du modÃ¨le (Cross-validation, mÃ©triques)\",\n",
    "    \"âœ… 8. DÃ©ploiement (Fichier de soumission Kaggle)\"\n",
    "]\n",
    "\n",
    "for step in steps_completed:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\nğŸ“ COMPÃ‰TENCES ML ACQUISES:\")\n",
    "skills = [\n",
    "    \"ğŸ“Š Analyse exploratoire des donnÃ©es (EDA)\",\n",
    "    \"ğŸ§¹ Preprocessing et nettoyage des donnÃ©es\", \n",
    "    \"âš—ï¸ Feature Engineering (crÃ©ation de nouvelles variables)\",\n",
    "    \"ğŸ·ï¸ Encoding des variables catÃ©gorielles\",\n",
    "    \"ğŸ¤– EntraÃ®nement de modÃ¨les ML supervisÃ©s\",\n",
    "    \"ğŸ“ˆ Ã‰valuation et comparaison de modÃ¨les\",\n",
    "    \"ğŸ¯ Optimisation et sÃ©lection du meilleur modÃ¨le\",\n",
    "    \"ğŸ“¤ PrÃ©paration d'une soumission Kaggle\"\n",
    "]\n",
    "\n",
    "for skill in skills:\n",
    "    print(f\"   {skill}\")\n",
    "\n",
    "print(\"\\nğŸŒŸ PROCHAINES Ã‰TAPES:\")\n",
    "print(\"   ğŸš€ Upload sur Kaggle et validation du score\")\n",
    "print(\"   ğŸ“ˆ Session 2: RÃ©gression pour prÃ©dire les notes\")\n",
    "print(\"   ğŸ¯ Session 3: Classification avancÃ©e avec plus d'algorithmes\")\n",
    "print(\"   ğŸ” Session 4: Clustering pour segmenter les Ã©tudiants\")\n",
    "\n",
    "print(\"\\nğŸ‰ FÃ‰LICITATIONS ! Vous avez crÃ©Ã© votre premier modÃ¨le ML complet ! ğŸ‰\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 8. RÃ©capitulatif et RÃ©flexions\n",
    "\n",
    "### âœ… Ce que nous avons accompli aujourd'hui :\n",
    "\n",
    "- [x] **ThÃ©orie ML** : DÃ©finitions, types d'IA, familles ML, workflow\n",
    "- [x] **Projet Pratique** : Analyse complÃ¨te du BAC Mauritanie 2022\n",
    "- [x] **EDA** : Exploration des donnÃ©es, visualisations, insights\n",
    "- [x] **Feature Engineering** : CrÃ©ation de nouvelles variables\n",
    "- [x] **ModÃ©lisation** : 4 algorithmes testÃ©s et comparÃ©s\n",
    "- [x] **Ã‰valuation** : MÃ©triques, validation croisÃ©e, sÃ©lection du meilleur modÃ¨le\n",
    "- [x] **DÃ©ploiement** : Fichier de soumission Kaggle prÃªt\n",
    "- [x] **Workflow ML complet** : De la dÃ©finition du problÃ¨me au dÃ©ploiement\n",
    "\n",
    "### â“ Questions de rÃ©flexion\n",
    "\n",
    "1. **Quel facteur influence le plus la rÃ©ussite au BAC selon notre analyse ?**\n",
    "\n",
    "_RÃ©ponse :_ Selon l'analyse d'importance des features, la moyenne gÃ©nÃ©rale et la rÃ©gularitÃ© des notes sont les facteurs les plus prÃ©dictifs.\n",
    "\n",
    "2. **Pourquoi avons-nous testÃ© plusieurs modÃ¨les ML ?**\n",
    "\n",
    "_RÃ©ponse :_ Chaque algorithme a ses forces et faiblesses. La comparaison permet de choisir le plus adaptÃ© Ã  notre problÃ¨me spÃ©cifique.\n",
    "\n",
    "3. **Comment amÃ©liorer encore notre modÃ¨le ?**\n",
    "\n",
    "_RÃ©ponse :_ Hyperparameter tuning, feature selection avancÃ©e, ensemble methods, plus de donnÃ©es d'entraÃ®nement.\n",
    "\n",
    "### ğŸ’¡ Insights Ã‰ducatifs DÃ©couverts :\n",
    "\n",
    "- Les disparitÃ©s rÃ©gionales sont rÃ©elles et mesurables\n",
    "- La rÃ©gularitÃ© des notes est aussi importante que la moyenne\n",
    "- Certaines matiÃ¨res sont plus prÃ©dictives que d'autres\n",
    "- L'IA peut aider Ã  identifier les Ã©tudiants Ã  risque\n",
    "\n",
    "### ğŸš€ Applications Futures :\n",
    "\n",
    "Ce type d'analyse peut Ãªtre utilisÃ© pour :\n",
    "- **SystÃ¨me d'alerte prÃ©coce** : Identifier les Ã©tudiants Ã  risque\n",
    "- **Optimisation pÃ©dagogique** : Adapter l'enseignement selon les besoins\n",
    "- **Politique Ã©ducative** : Cibler les rÃ©gions nÃ©cessitant plus de ressources\n",
    "- **Orientation** : Conseiller les Ã©tudiants sur leurs forces/faiblesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Ressources pour aller plus loin\n",
    "\n",
    "### ğŸ“– Lectures recommandÃ©es :\n",
    "- [Cours CS229 de Stanford](https://cs229.stanford.edu/)\n",
    "- [Introduction to Statistical Learning](https://www.statlearning.com/)\n",
    "- [Kaggle Learn - Machine Learning](https://www.kaggle.com/learn/machine-learning)\n",
    "\n",
    "### ğŸ¥ VidÃ©os :\n",
    "- [3Blue1Brown - Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "- [Andrew Ng - Machine Learning Course](https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "### ğŸ—ï¸ Prochaine session :\n",
    "**Session 2 - RÃ©gression et PrÃ©diction**\n",
    "- RÃ©gression linÃ©aire et polynomiale\n",
    "- MÃ©triques d'Ã©valuation (RMSE, MAE, RÂ²)\n",
    "- Cas pratique : prÃ©diction des notes individuelles\n",
    "- RÃ©gularisation (Ridge, Lasso)\n",
    "\n",
    "### ğŸ† DÃ©fi pour la maison :\n",
    "1. **Uploadez votre soumission sur Kaggle** et partagez votre score !\n",
    "2. **Essayez d'amÃ©liorer le modÃ¨le** en crÃ©ant de nouvelles features\n",
    "3. **Analysez les erreurs** : quels Ã©tudiants sont mal classifiÃ©s et pourquoi ?\n",
    "4. **Explorez d'autres algorithmes** : SVM, XGBoost, Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“§ Contact :** mohamed.beydia@vela-learning.com  \n",
    "**ğŸŒ Vela Learning :** [https://vela-learning.com](https://vela-learning.com)  \n",
    "**ğŸ“ SupNum Nouakchott**\n",
    "\n",
    "**ğŸ‰ Bravo pour votre premiÃ¨re rÃ©alisation en Machine Learning ! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
