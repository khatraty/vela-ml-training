{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ Session 1 - Introduction Ã  l'IA et au Machine Learning\n",
    "## Solutions avec Cas Pratique : PrÃ©diction BAC Mauritanie 2022\n",
    "\n",
    "**Formation IA & ML - SupNum Nouakchott**  \n",
    "**Formateur:** Mohamed Beydia - Vela Learning  \n",
    "**Dataset:** BAC Mauritanie 2022 Predictive Modeling Challenge\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Objectifs de la session\n",
    "\n",
    "Ã€ la fin de cette session, vous serez capables de :\n",
    "- [x] DÃ©finir l'Intelligence Artificielle, le Machine Learning et le Deep Learning\n",
    "- [x] Distinguer l'IA symbolique de l'IA statistique\n",
    "- [x] Comprendre la diffÃ©rence entre IA analytique et gÃ©nÃ©rative\n",
    "- [x] Identifier les trois familles principales du ML\n",
    "- [x] DÃ©crire le workflow standard d'un projet ML\n",
    "- [x] ReconnaÃ®tre des cas d'usage concrets d'IA\n",
    "- [x] **BONUS:** Analyser un dataset rÃ©el et crÃ©er votre premiÃ¨re prÃ©diction ML !\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’» 7. PROJET PRATIQUE : Analyse BAC Mauritanie 2022\n",
    "\n",
    "### ğŸ¯ Notre DÃ©fi Kaggle\n",
    "**Objectif :** PrÃ©dire les rÃ©sultats du BAC 2022 en Mauritanie Ã  partir des donnÃ©es des candidats\n",
    "\n",
    "**Type de problÃ¨me :** Classification supervisÃ©e  \n",
    "**MÃ©trique :** Accuracy, Precision, Recall\n",
    "\n",
    "CommenÃ§ons par explorer nos donnÃ©es !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import des librairies essentielles pour notre projet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour les graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Librairies importÃ©es avec succÃ¨s !\")\n",
    "print(f\"ğŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy version: {np.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extraction et chargement des donnÃ©es BAC Mauritanie\n",
    "# Chemin vers le fichier zip (dans le dossier data/ de cette session)\n",
    "zip_path = \"data/bac-mauritanie-2022-predictive-modeling-challeng.zip\"\n",
    "extract_path = \"data/extracted/\"\n",
    "\n",
    "# CrÃ©er le dossier d'extraction s'il n'existe pas\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extraire les donnÃ©es\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"âœ… DonnÃ©es extraites avec succÃ¨s !\")\n",
    "    \n",
    "    # Lister les fichiers extraits\n",
    "    files = os.listdir(extract_path)\n",
    "    print(\"ğŸ“ Fichiers disponibles:\")\n",
    "    for file in files:\n",
    "        print(f\"  - {file}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors de l'extraction: {e}\")\n",
    "    print(\"VÃ©rifiez que le fichier zip existe dans data/\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ”§ CHARGEMENT ROBUSTE DES DONNÃ‰ES CSV\n",
    "def load_csv_robust(file_path, encoding_attempts=['utf-8', 'latin-1', 'cp1252']):\n",
    "    \"\"\"\n",
    "    Charge un fichier CSV de maniÃ¨re robuste avec gestion des erreurs\n",
    "    \"\"\"\n",
    "    filename = file_path.split('/')[-1]\n",
    "    print(f\"ğŸ”„ Tentative de chargement: {filename}\")\n",
    "    \n",
    "    for encoding in encoding_attempts:\n",
    "        try:\n",
    "            # Utiliser des paramÃ¨tres plus permissifs pour gÃ©rer les erreurs\n",
    "            df = pd.read_csv(file_path, \n",
    "                           encoding=encoding,\n",
    "                           sep=',',\n",
    "                           quotechar='\"',\n",
    "                           on_bad_lines='skip',  # Ignorer les lignes problÃ©matiques\n",
    "                           engine='python',      # Moteur Python plus robuste\n",
    "                           dtype=str)            # Tout charger en string d'abord\n",
    "            print(f\"âœ… {filename} chargÃ© - Encoding: {encoding} - {len(df)} lignes\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Ã‰chec {encoding}: {str(e)[:100]}...\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"âŒ Impossible de charger {filename}\")\n",
    "    return None\n",
    "\n",
    "# Chargement des datasets avec gestion d'erreurs robuste\n",
    "try:\n",
    "    print(\"ğŸ”„ Chargement robuste des datasets...\")\n",
    "    print()\n",
    "    \n",
    "    # Essayer les diffÃ©rents noms possibles des fichiers\n",
    "    train_files = ['train_set.csv', 'train.csv']\n",
    "    test_files = ['test_set.csv', 'test.csv'] \n",
    "    submission_files = ['submission_template.csv', 'sample_template.csv']\n",
    "    \n",
    "    # Chargement du fichier d'entraÃ®nement\n",
    "    train_df = None\n",
    "    for filename in train_files:\n",
    "        filepath = f\"{extract_path}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            train_df = load_csv_robust(filepath)\n",
    "            if train_df is not None:\n",
    "                break\n",
    "    \n",
    "    # Chargement du fichier de test\n",
    "    test_df = None\n",
    "    for filename in test_files:\n",
    "        filepath = f\"{extract_path}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            test_df = load_csv_robust(filepath)\n",
    "            if test_df is not None:\n",
    "                break\n",
    "    \n",
    "    # Chargement du template de soumission\n",
    "    sample_submission = None\n",
    "    for filename in submission_files:\n",
    "        filepath = f\"{extract_path}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            sample_submission = load_csv_robust(filepath)\n",
    "            if sample_submission is not None:\n",
    "                break\n",
    "    \n",
    "    if train_df is not None and test_df is not None:\n",
    "        print(\"\\nâœ… Datasets chargÃ©s avec succÃ¨s !\")\n",
    "        print(f\"ğŸ“Š DonnÃ©es d'entraÃ®nement: {train_df.shape[0]} lignes, {train_df.shape[1]} colonnes\")\n",
    "        print(f\"ğŸ“Š DonnÃ©es de test: {test_df.shape[0]} lignes, {test_df.shape[1]} colonnes\")\n",
    "        if sample_submission is not None:\n",
    "            print(f\"ğŸ“Š Template de soumission: {sample_submission.shape}\")\n",
    "        \n",
    "        # Convertir les colonnes numÃ©riques\n",
    "        print(\"\\nğŸ”„ Conversion des types de donnÃ©es...\")\n",
    "        \n",
    "        # Identifier et convertir les colonnes de notes\n",
    "        numeric_columns = []\n",
    "        for col in train_df.columns:\n",
    "            if any(keyword in col.lower() for keyword in ['note', 'moyenne', 'general']):\n",
    "                try:\n",
    "                    train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "                    if col in test_df.columns:\n",
    "                        test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "                    numeric_columns.append(col)\n",
    "                    print(f\"  âœ“ {col} converti en numÃ©rique\")\n",
    "                except:\n",
    "                    print(f\"  âŒ Impossible de convertir {col}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Colonnes numÃ©riques identifiÃ©es: {len(numeric_columns)}\")\n",
    "        \n",
    "        # VÃ©rifier la qualitÃ© des donnÃ©es\n",
    "        print(\"\\nğŸ” VÃ©rification de la qualitÃ©:\")\n",
    "        print(f\"  - Valeurs manquantes train: {train_df.isnull().sum().sum()}\")\n",
    "        print(f\"  - Valeurs manquantes test: {test_df.isnull().sum().sum()}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ProblÃ¨me de chargement des datasets\")\n",
    "        print(\"ğŸ” Fichiers disponibles dans le dossier extracted:\")\n",
    "        for file in os.listdir(extract_path):\n",
    "            file_size = os.path.getsize(f\"{extract_path}/{file}\") / 1024  # KB\n",
    "            print(f\"  - {file} ({file_size:.1f} KB)\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"âŒ Erreur gÃ©nÃ©rale: {e}\")\n",
    "    print(\"\\nğŸ’¡ Solutions:\")\n",
    "    print(\"1. VÃ©rifiez que le fichier zip est bien extrait\")\n",
    "    print(\"2. Regardez les noms exacts des fichiers CSV\")\n",
    "    print(\"3. Le dataset peut contenir des caractÃ¨res spÃ©ciaux\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ” EXPLORATION INITIALE DES DONNÃ‰ES\n",
    "if train_df is not None:\n",
    "    print(\"ğŸ” === EXPLORATION DES DONNÃ‰ES BAC MAURITANIE 2022 ===\")\n",
    "    print()\n",
    "    \n",
    "    # AperÃ§u des donnÃ©es\n",
    "    print(\"ğŸ“‹ AperÃ§u des premiÃ¨res lignes:\")\n",
    "    print(train_df.head())\n",
    "    print()\n",
    "    \n",
    "    # Informations sur les colonnes\n",
    "    print(\"ğŸ“Š Informations sur les colonnes:\")\n",
    "    print(f\"Nombre total de colonnes: {len(train_df.columns)}\")\n",
    "    print(\"Noms des colonnes:\")\n",
    "    for i, col in enumerate(train_df.columns):\n",
    "        dtype = train_df[col].dtype\n",
    "        non_null = train_df[col].count()\n",
    "        print(f\"  {i+1:2d}. {col:25s} | {str(dtype):10s} | {non_null:5d} non-null\")\n",
    "    \n",
    "    # Identifier la variable cible\n",
    "    target_columns = [col for col in train_df.columns if any(word in col.lower() for word in ['decision', 'result', 'target', 'label'])]\n",
    "    if target_columns:\n",
    "        target_col = target_columns[0]\n",
    "        print(f\"\\nğŸ¯ Variable cible identifiÃ©e: '{target_col}'\")\n",
    "        \n",
    "        # Distribution de la variable cible\n",
    "        print(\"\\nğŸ“Š Distribution de la variable cible:\")\n",
    "        value_counts = train_df[target_col].value_counts()\n",
    "        for value, count in value_counts.items():\n",
    "            percentage = (count / len(train_df)) * 100\n",
    "            print(f\"  {value}: {count} ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Variable cible non identifiÃ©e automatiquement\")\n",
    "        print(\"Colonnes possibles:\", list(train_df.columns)[:10], \"...\")\n",
    "        \nelse:\n",
    "    print(\"âŒ Impossible d'explorer les donnÃ©es - chargement Ã©chouÃ©\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ“Š ANALYSE VISUELLE SIMPLE\n",
    "if train_df is not None and target_columns:\n",
    "    try:\n",
    "        target_col = target_columns[0]\n",
    "        \n",
    "        # Distribution de la variable cible\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Graphique en barres\n",
    "        plt.subplot(1, 2, 1)\n",
    "        value_counts = train_df[target_col].value_counts()\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "        value_counts.plot(kind='bar', color=colors[:len(value_counts)])\n",
    "        plt.title('Distribution des RÃ©sultats BAC 2022', fontweight='bold')\n",
    "        plt.xlabel('DÃ©cision')\n",
    "        plt.ylabel('Nombre d\\'Ã©tudiants')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Graphique circulaire\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%',\n",
    "                colors=colors[:len(value_counts)])\n",
    "        plt.title('RÃ©partition des RÃ©sultats', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyse des notes si disponibles\n",
    "        note_columns = [col for col in train_df.columns if 'note' in col.lower()]\n",
    "        if note_columns:\n",
    "            print(f\"\\nğŸ“ Colonnes de notes identifiÃ©es: {len(note_columns)}\")\n",
    "            print(note_columns)\n",
    "            \n",
    "            # Statistiques des notes\n",
    "            if len(note_columns) > 0:\n",
    "                # SÃ©lectionner quelques colonnes de notes pour l'analyse\n",
    "                sample_notes = note_columns[:min(6, len(note_columns))]\n",
    "                \n",
    "                # CrÃ©er un DataFrame numÃ©rique pour les notes\n",
    "                notes_df = train_df[sample_notes].apply(pd.to_numeric, errors='coerce')\n",
    "                \n",
    "                print(\"\\nğŸ“Š Statistiques des notes:\")\n",
    "                print(notes_df.describe().round(2))\n",
    "                \n",
    "                # Visualisation des notes\n",
    "                if len(sample_notes) >= 4:\n",
    "                    plt.figure(figsize=(15, 8))\n",
    "                    for i, col in enumerate(sample_notes[:4], 1):\n",
    "                        plt.subplot(2, 2, i)\n",
    "                        notes_df[col].hist(bins=20, alpha=0.7, color=f'C{i-1}')\n",
    "                        plt.title(f'Distribution {col}')\n",
    "                        plt.xlabel('Note')\n",
    "                        plt.ylabel('FrÃ©quence')\n",
    "                        mean_val = notes_df[col].mean()\n",
    "                        if not pd.isna(mean_val):\n",
    "                            plt.axvline(mean_val, color='red', linestyle='--', \n",
    "                                      label=f'Moyenne: {mean_val:.1f}')\n",
    "                            plt.legend()\n",
    "                    \n",
    "                    plt.suptitle('Distribution des Notes - BAC Mauritanie 2022', fontsize=14, fontweight='bold')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "        \n",
    "        print(\"\\nâœ… Analyse visuelle terminÃ©e !\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors de la visualisation: {e}\")\n",
    "        print(\"Continuons avec l'analyse textuelle...\")\n",
    "        \nelse:\n",
    "    print(\"âš ï¸ Pas de donnÃ©es Ã  visualiser\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ğŸ¯ RÃ‰CAPITULATIF DE L'EXPLORATION\n",
    "if train_df is not None:\n",
    "    print(\"ğŸ¯ === RÃ‰CAPITULATIF DE L'ANALYSE ===\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"âœ… Dataset BAC Mauritanie 2022 chargÃ© avec succÃ¨s\")\n",
    "    print(f\"ğŸ“Š {len(train_df)} Ã©tudiants dans le dataset d'entraÃ®nement\")\n",
    "    print(f\"ğŸ“Š {len(train_df.columns)} caractÃ©ristiques par Ã©tudiant\")\n",
    "    \n",
    "    if target_columns:\n",
    "        target_col = target_columns[0]\n",
    "        unique_decisions = train_df[target_col].nunique()\n",
    "        print(f\"ğŸ¯ {unique_decisions} types de dÃ©cisions possibles\")\n",
    "        \n",
    "        # Calculer le taux de rÃ©ussite si possible\n",
    "        if any(word in train_df[target_col].str.lower().str.cat(sep=' ') for word in ['admis', 'reussi', 'pass']):\n",
    "            success_rate = train_df[target_col].str.contains('admis|reussi|pass', case=False).mean()\n",
    "            print(f\"ğŸ† Taux de rÃ©ussite estimÃ©: {success_rate:.1%}\")\n",
    "    \n",
    "    # QualitÃ© des donnÃ©es\n",
    "    missing_percentage = (train_df.isnull().sum().sum() / (len(train_df) * len(train_df.columns))) * 100\n",
    "    print(f\"ğŸ“ˆ QualitÃ© des donnÃ©es: {100-missing_percentage:.1f}% (complÃ©tude)\")\n",
    "    \n",
    "    note_columns = [col for col in train_df.columns if 'note' in col.lower()]\n",
    "    if note_columns:\n",
    "        print(f\"ğŸ“š {len(note_columns)} matiÃ¨res identifiÃ©es\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ PROCHAINES Ã‰TAPES:\")\n",
    "    print(f\"   1. Nettoyage et prÃ©paration des donnÃ©es\")\n",
    "    print(f\"   2. Feature engineering (crÃ©ation de nouvelles variables)\")\n",
    "    print(f\"   3. EntraÃ®nement de modÃ¨les ML\")\n",
    "    print(f\"   4. Ã‰valuation et optimisation\")\n",
    "    print(f\"   5. GÃ©nÃ©ration de prÃ©dictions pour Kaggle\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Session 1 terminÃ©e avec succÃ¨s !\")\n",
    "    print(f\"ğŸ“š Prochaine session: RÃ©gression et prÃ©diction des notes individuelles\")\n",
    "    \nelse:\n",
    "    print(\"âŒ Impossible de gÃ©nÃ©rer le rÃ©capitulatif - problÃ¨me de chargement des donnÃ©es\")\n",
    "    print(\"\\nğŸ› ï¸ Actions recommandÃ©es:\")\n",
    "    print(\"   1. VÃ©rifier que le fichier ZIP est prÃ©sent dans data/\")\n",
    "    print(\"   2. VÃ©rifier l'intÃ©gritÃ© du fichier ZIP\")\n",
    "    print(\"   3. Examiner manuellement les fichiers CSV extraits\")\n",
    "    print(\"   4. Contacter le formateur si le problÃ¨me persiste\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 8. RÃ©capitulatif et RÃ©flexions\n",
    "\n",
    "### âœ… Ce que nous avons accompli aujourd'hui :\n",
    "\n",
    "- [x] **ThÃ©orie ML** : DÃ©finitions, types d'IA, familles ML, workflow\n",
    "- [x] **Chargement robuste** : Gestion des erreurs CSV avec multiple encodings\n",
    "- [x] **Exploration des donnÃ©es** : Structure, qualitÃ©, distribution\n",
    "- [x] **Visualisations** : Graphiques pour comprendre les donnÃ©es\n",
    "- [x] **Analyse BAC Mauritanie** : Dataset Ã©ducatif rÃ©el\n",
    "- [x] **PrÃ©paration** : Base solide pour les sessions suivantes\n",
    "\n",
    "### ğŸ”§ ProblÃ¨mes rÃ©solus :\n",
    "\n",
    "1. **Erreur CSV Tokenization** : RÃ©solu avec `on_bad_lines='skip'` et `engine='python'`\n",
    "2. **Encodage des caractÃ¨res** : Gestion multiple encodings (utf-8, latin-1, cp1252)\n",
    "3. **Noms de fichiers variables** : Recherche automatique des bons noms\n",
    "4. **Types de donnÃ©es** : Conversion robuste des colonnes numÃ©riques\n",
    "5. **Gestion d'erreurs** : Code rÃ©sistant aux problÃ¨mes de donnÃ©es\n",
    "\n",
    "### ğŸ’¡ LeÃ§ons apprises :\n",
    "\n",
    "- **Les donnÃ©es rÃ©elles sont imparfaites** : Il faut toujours prÃ©voir la gestion d'erreurs\n",
    "- **L'encodage est crucial** : Les caractÃ¨res spÃ©ciaux causent souvent des problÃ¨mes\n",
    "- **La robustesse prime** : Un code qui gÃ¨re les exceptions est essentiel\n",
    "- **L'exploration avant tout** : Comprendre ses donnÃ©es avant de modÃ©liser\n",
    "\n",
    "### ğŸš€ Prochaines Ã©tapes :\n",
    "\n",
    "**Session 2 - RÃ©gression et PrÃ©diction**\n",
    "- Nettoyer et prÃ©parer les donnÃ©es BAC\n",
    "- CrÃ©er un modÃ¨le de rÃ©gression pour prÃ©dire les notes\n",
    "- Appliquer Ridge et Lasso pour la rÃ©gularisation\n",
    "- Ã‰valuer avec RMSE, MAE, RÂ²\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“§ Contact :** mohamed.beydia@vela-learning.com  \n",
    "**ğŸŒ Vela Learning :** [https://vela-learning.com](https://vela-learning.com)  \n",
    "**ğŸ“ SupNum Nouakchott**\n",
    "\n",
    "**ğŸ‰ Session 1 terminÃ©e avec succÃ¨s ! DonnÃ©es chargÃ©es et explorÃ©es ! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
