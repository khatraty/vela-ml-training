{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Session 1 - Introduction √† l'IA et au Machine Learning\n",
    "## Solutions avec Cas Pratique : Pr√©diction BAC Mauritanie 2022\n",
    "\n",
    "**Formation IA & ML - SupNum Nouakchott**  \n",
    "**Formateur:** Mohamed Beydia - Vela Learning  \n",
    "**Dataset:** BAC Mauritanie 2022 Predictive Modeling Challenge\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Objectifs de la session\n",
    "\n",
    "√Ä la fin de cette session, vous serez capables de :\n",
    "- [x] D√©finir l'Intelligence Artificielle, le Machine Learning et le Deep Learning\n",
    "- [x] Distinguer l'IA symbolique de l'IA statistique\n",
    "- [x] Comprendre la diff√©rence entre IA analytique et g√©n√©rative\n",
    "- [x] Identifier les trois familles principales du ML\n",
    "- [x] D√©crire le workflow standard d'un projet ML\n",
    "- [x] Reconna√Ætre des cas d'usage concrets d'IA\n",
    "- [x] **BONUS:** Analyser un dataset r√©el et cr√©er votre premi√®re pr√©diction ML !\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª 7. PROJET PRATIQUE : Analyse BAC Mauritanie 2022\n",
    "\n",
    "### üéØ Notre D√©fi Kaggle\n",
    "**Objectif :** Pr√©dire les r√©sultats du BAC 2022 en Mauritanie √† partir des donn√©es des candidats\n",
    "\n",
    "**Type de probl√®me :** Classification supervis√©e  \n",
    "**M√©trique :** Accuracy, Precision, Recall\n",
    "\n",
    "Commen√ßons par explorer nos donn√©es !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import des librairies essentielles pour notre projet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour les graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Librairies import√©es avec succ√®s !\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extraction et chargement des donn√©es BAC Mauritanie\n",
    "# Chemin vers le fichier zip (dans le dossier data/ de cette session)\n",
    "zip_path = \"data/bac-mauritanie-2022-predictive-modeling-challeng.zip\"\n",
    "extract_path = \"data/extracted/\"\n",
    "\n",
    "# Cr√©er le dossier d'extraction s'il n'existe pas\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extraire les donn√©es\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"‚úÖ Donn√©es extraites avec succ√®s !\")\n",
    "    \n",
    "    # Lister les fichiers extraits\n",
    "    files = os.listdir(extract_path)\n",
    "    print(\"üìÅ Fichiers disponibles:\")\n",
    "    for file in files:\n",
    "        print(f\"  - {file}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors de l'extraction: {e}\")\n",
    "    print(\"V√©rifiez que le fichier zip existe dans data/\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# üîß CHARGEMENT ROBUSTE DES DONN√âES CSV\n",
    "def load_csv_robust(file_path, encoding_attempts=['utf-8', 'latin-1', 'cp1252']):\n",
    "    \"\"\"\n",
    "    Charge un fichier CSV de mani√®re robuste avec gestion des erreurs\n",
    "    \"\"\"\n",
    "    filename = file_path.split('/')[-1]\n",
    "    print(f\"üîÑ Tentative de chargement: {filename}\")\n",
    "    \n",
    "    for encoding in encoding_attempts:\n",
    "        try:\n",
    "            # Utiliser des param√®tres plus permissifs pour g√©rer les erreurs\n",
    "            df = pd.read_csv(file_path, \n",
    "                           encoding=encoding,\n",
    "                           sep=',',\n",
    "                           quotechar='\"',\n",
    "                           on_bad_lines='skip',  # Ignorer les lignes probl√©matiques\n",
    "                           engine='python',      # Moteur Python plus robuste\n",
    "                           dtype=str)            # Tout charger en string d'abord\n",
    "            print(f\"‚úÖ {filename} charg√© - Encoding: {encoding} - {len(df)} lignes\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå √âchec {encoding}: {str(e)[:100]}...\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚ùå Impossible de charger {filename}\")\n",
    "    return None\n",
    "\n",
    "# Chargement des datasets avec gestion d'erreurs robuste\n",
    "try:\n",
    "    print(\"üîÑ Chargement robuste des datasets...\")\n",
    "    print()\n",
    "    \n",
    "    # Essayer les diff√©rents noms possibles des fichiers\n",
    "    train_files = ['train_set.csv', 'train.csv']\n",
    "    test_files = ['test_set.csv', 'test.csv'] \n",
    "    submission_files = ['submission_template.csv', 'sample_template.csv']\n",
    "    \n",
    "    # Chargement du fichier d'entra√Ænement\n",
    "    train_df = None\n",
    "    for filename in train_files:\n",
    "        filepath = f\"{extract_path}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            train_df = load_csv_robust(filepath)\n",
    "            if train_df is not None:\n",
    "                break\n",
    "    \n",
    "    # Chargement du fichier de test\n",
    "    test_df = None\n",
    "    for filename in test_files:\n",
    "        filepath = f\"{extract_path}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            test_df = load_csv_robust(filepath)\n",
    "            if test_df is not None:\n",
    "                break\n",
    "    \n",
    "    # Chargement du template de soumission\n",
    "    sample_submission = None\n",
    "    for filename in submission_files:\n",
    "        filepath = f\"{extract_path}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            sample_submission = load_csv_robust(filepath)\n",
    "            if sample_submission is not None:\n",
    "                break\n",
    "    \n",
    "    if train_df is not None and test_df is not None:\n",
    "        print(\"\\n‚úÖ Datasets charg√©s avec succ√®s !\")\n",
    "        print(f\"üìä Donn√©es d'entra√Ænement: {train_df.shape[0]} lignes, {train_df.shape[1]} colonnes\")\n",
    "        print(f\"üìä Donn√©es de test: {test_df.shape[0]} lignes, {test_df.shape[1]} colonnes\")\n",
    "        if sample_submission is not None:\n",
    "            print(f\"üìä Template de soumission: {sample_submission.shape}\")\n",
    "        \n",
    "        # Convertir les colonnes num√©riques\n",
    "        print(\"\\nüîÑ Conversion des types de donn√©es...\")\n",
    "        \n",
    "        # Identifier et convertir les colonnes de notes\n",
    "        numeric_columns = []\n",
    "        for col in train_df.columns:\n",
    "            if any(keyword in col.lower() for keyword in ['note', 'moyenne', 'general']):\n",
    "                try:\n",
    "                    train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "                    if col in test_df.columns:\n",
    "                        test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "                    numeric_columns.append(col)\n",
    "                    print(f\"  ‚úì {col} converti en num√©rique\")\n",
    "                except:\n",
    "                    print(f\"  ‚ùå Impossible de convertir {col}\")\n",
    "        \n",
    "        print(f\"\\nüìä Colonnes num√©riques identifi√©es: {len(numeric_columns)}\")\n",
    "        \n",
    "        # V√©rifier la qualit√© des donn√©es\n",
    "        print(\"\\nüîç V√©rification de la qualit√©:\")\n",
    "        print(f\"  - Valeurs manquantes train: {train_df.isnull().sum().sum()}\")\n",
    "        print(f\"  - Valeurs manquantes test: {test_df.isnull().sum().sum()}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Probl√®me de chargement des datasets\")\n",
    "        print(\"üîç Fichiers disponibles dans le dossier extracted:\")\n",
    "        for file in os.listdir(extract_path):\n",
    "            file_size = os.path.getsize(f\"{extract_path}/{file}\") / 1024  # KB\n",
    "            print(f\"  - {file} ({file_size:.1f} KB)\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"‚ùå Erreur g√©n√©rale: {e}\")\n",
    "    print(\"\\nüí° Solutions:\")\n",
    "    print(\"1. V√©rifiez que le fichier zip est bien extrait\")\n",
    "    print(\"2. Regardez les noms exacts des fichiers CSV\")\n",
    "    print(\"3. Le dataset peut contenir des caract√®res sp√©ciaux\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# üîç EXPLORATION INITIALE DES DONN√âES\n",
    "if train_df is not None:\n",
    "    print(\"üîç === EXPLORATION DES DONN√âES BAC MAURITANIE 2022 ===\")\n",
    "    print()\n",
    "    \n",
    "    # Aper√ßu des donn√©es\n",
    "    print(\"üìã Aper√ßu des premi√®res lignes:\")\n",
    "    print(train_df.head())\n",
    "    print()\n",
    "    \n",
    "    # Informations sur les colonnes\n",
    "    print(\"üìä Informations sur les colonnes:\")\n",
    "    print(f\"Nombre total de colonnes: {len(train_df.columns)}\")\n",
    "    print(\"Noms des colonnes:\")\n",
    "    for i, col in enumerate(train_df.columns):\n",
    "        dtype = train_df[col].dtype\n",
    "        non_null = train_df[col].count()\n",
    "        print(f\"  {i+1:2d}. {col:25s} | {str(dtype):10s} | {non_null:5d} non-null\")\n",
    "    \n",
    "    # Identifier la variable cible\n",
    "    target_columns = [col for col in train_df.columns if any(word in col.lower() for word in ['decision', 'result', 'target', 'label'])]\n",
    "    if target_columns:\n",
    "        target_col = target_columns[0]\n",
    "        print(f\"\\nüéØ Variable cible identifi√©e: '{target_col}'\")\n",
    "        \n",
    "        # Distribution de la variable cible\n",
    "        print(\"\\nüìä Distribution de la variable cible:\")\n",
    "        value_counts = train_df[target_col].value_counts()\n",
    "        for value, count in value_counts.items():\n",
    "            percentage = (count / len(train_df)) * 100\n",
    "            print(f\"  {value}: {count} ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Variable cible non identifi√©e automatiquement\")\n",
    "        print(\"Colonnes possibles:\", list(train_df.columns)[:10], \"...\")\n",
    "        \nelse:\n",
    "    print(\"‚ùå Impossible d'explorer les donn√©es - chargement √©chou√©\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# üìä ANALYSE VISUELLE SIMPLE\n",
    "if train_df is not None and target_columns:\n",
    "    try:\n",
    "        target_col = target_columns[0]\n",
    "        \n",
    "        # Distribution de la variable cible\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Graphique en barres\n",
    "        plt.subplot(1, 2, 1)\n",
    "        value_counts = train_df[target_col].value_counts()\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "        value_counts.plot(kind='bar', color=colors[:len(value_counts)])\n",
    "        plt.title('Distribution des R√©sultats BAC 2022', fontweight='bold')\n",
    "        plt.xlabel('D√©cision')\n",
    "        plt.ylabel('Nombre d\\'√©tudiants')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Graphique circulaire\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%',\n",
    "                colors=colors[:len(value_counts)])\n",
    "        plt.title('R√©partition des R√©sultats', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyse des notes si disponibles\n",
    "        note_columns = [col for col in train_df.columns if 'note' in col.lower()]\n",
    "        if note_columns:\n",
    "            print(f\"\\nüìù Colonnes de notes identifi√©es: {len(note_columns)}\")\n",
    "            print(note_columns)\n",
    "            \n",
    "            # Statistiques des notes\n",
    "            if len(note_columns) > 0:\n",
    "                # S√©lectionner quelques colonnes de notes pour l'analyse\n",
    "                sample_notes = note_columns[:min(6, len(note_columns))]\n",
    "                \n",
    "                # Cr√©er un DataFrame num√©rique pour les notes\n",
    "                notes_df = train_df[sample_notes].apply(pd.to_numeric, errors='coerce')\n",
    "                \n",
    "                print(\"\\nüìä Statistiques des notes:\")\n",
    "                print(notes_df.describe().round(2))\n",
    "                \n",
    "                # Visualisation des notes\n",
    "                if len(sample_notes) >= 4:\n",
    "                    plt.figure(figsize=(15, 8))\n",
    "                    for i, col in enumerate(sample_notes[:4], 1):\n",
    "                        plt.subplot(2, 2, i)\n",
    "                        notes_df[col].hist(bins=20, alpha=0.7, color=f'C{i-1}')\n",
    "                        plt.title(f'Distribution {col}')\n",
    "                        plt.xlabel('Note')\n",
    "                        plt.ylabel('Fr√©quence')\n",
    "                        mean_val = notes_df[col].mean()\n",
    "                        if not pd.isna(mean_val):\n",
    "                            plt.axvline(mean_val, color='red', linestyle='--', \n",
    "                                      label=f'Moyenne: {mean_val:.1f}')\n",
    "                            plt.legend()\n",
    "                    \n",
    "                    plt.suptitle('Distribution des Notes - BAC Mauritanie 2022', fontsize=14, fontweight='bold')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "        \n",
    "        print(\"\\n‚úÖ Analyse visuelle termin√©e !\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la visualisation: {e}\")\n",
    "        print(\"Continuons avec l'analyse textuelle...\")\n",
    "        \nelse:\n",
    "    print(\"‚ö†Ô∏è Pas de donn√©es √† visualiser\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# üéØ R√âCAPITULATIF DE L'EXPLORATION\n",
    "if train_df is not None:\n",
    "    print(\"üéØ === R√âCAPITULATIF DE L'ANALYSE ===\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"‚úÖ Dataset BAC Mauritanie 2022 charg√© avec succ√®s\")\n",
    "    print(f\"üìä {len(train_df)} √©tudiants dans le dataset d'entra√Ænement\")\n",
    "    print(f\"üìä {len(train_df.columns)} caract√©ristiques par √©tudiant\")\n",
    "    \n",
    "    if target_columns:\n",
    "        target_col = target_columns[0]\n",
    "        unique_decisions = train_df[target_col].nunique()\n",
    "        print(f\"üéØ {unique_decisions} types de d√©cisions possibles\")\n",
    "        \n",
    "        # Calculer le taux de r√©ussite si possible\n",
    "        if any(word in train_df[target_col].str.lower().str.cat(sep=' ') for word in ['admis', 'reussi', 'pass']):\n",
    "            success_rate = train_df[target_col].str.contains('admis|reussi|pass', case=False).mean()\n",
    "            print(f\"üèÜ Taux de r√©ussite estim√©: {success_rate:.1%}\")\n",
    "    \n",
    "    # Qualit√© des donn√©es\n",
    "    missing_percentage = (train_df.isnull().sum().sum() / (len(train_df) * len(train_df.columns))) * 100\n",
    "    print(f\"üìà Qualit√© des donn√©es: {100-missing_percentage:.1f}% (compl√©tude)\")\n",
    "    \n",
    "    note_columns = [col for col in train_df.columns if 'note' in col.lower()]\n",
    "    if note_columns:\n",
    "        print(f\"üìö {len(note_columns)} mati√®res identifi√©es\")\n",
    "    \n",
    "    print(f\"\\nüí° PROCHAINES √âTAPES:\")\n",
    "    print(f\"   1. Nettoyage et pr√©paration des donn√©es\")\n",
    "    print(f\"   2. Feature engineering (cr√©ation de nouvelles variables)\")\n",
    "    print(f\"   3. Entra√Ænement de mod√®les ML\")\n",
    "    print(f\"   4. √âvaluation et optimisation\")\n",
    "    print(f\"   5. G√©n√©ration de pr√©dictions pour Kaggle\")\n",
    "    \n",
    "    print(f\"\\nüéâ Session 1 termin√©e avec succ√®s !\")\n",
    "    print(f\"üìö Prochaine session: R√©gression et pr√©diction des notes individuelles\")\n",
    "    \nelse:\n",
    "    print(\"‚ùå Impossible de g√©n√©rer le r√©capitulatif - probl√®me de chargement des donn√©es\")\n",
    "    print(\"\\nüõ†Ô∏è Actions recommand√©es:\")\n",
    "    print(\"   1. V√©rifier que le fichier ZIP est pr√©sent dans data/\")\n",
    "    print(\"   2. V√©rifier l'int√©grit√© du fichier ZIP\")\n",
    "    print(\"   3. Examiner manuellement les fichiers CSV extraits\")\n",
    "    print(\"   4. Contacter le formateur si le probl√®me persiste\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 8. R√©capitulatif et R√©flexions\n",
    "\n",
    "### ‚úÖ Ce que nous avons accompli aujourd'hui :\n",
    "\n",
    "- [x] **Th√©orie ML** : D√©finitions, types d'IA, familles ML, workflow\n",
    "- [x] **Chargement robuste** : Gestion des erreurs CSV avec multiple encodings\n",
    "- [x] **Exploration des donn√©es** : Structure, qualit√©, distribution\n",
    "- [x] **Visualisations** : Graphiques pour comprendre les donn√©es\n",
    "- [x] **Analyse BAC Mauritanie** : Dataset √©ducatif r√©el\n",
    "- [x] **Pr√©paration** : Base solide pour les sessions suivantes\n",
    "\n",
    "### üîß Probl√®mes r√©solus :\n",
    "\n",
    "1. **Erreur CSV Tokenization** : R√©solu avec `on_bad_lines='skip'` et `engine='python'`\n",
    "2. **Encodage des caract√®res** : Gestion multiple encodings (utf-8, latin-1, cp1252)\n",
    "3. **Noms de fichiers variables** : Recherche automatique des bons noms\n",
    "4. **Types de donn√©es** : Conversion robuste des colonnes num√©riques\n",
    "5. **Gestion d'erreurs** : Code r√©sistant aux probl√®mes de donn√©es\n",
    "\n",
    "### üí° Le√ßons apprises :\n",
    "\n",
    "- **Les donn√©es r√©elles sont imparfaites** : Il faut toujours pr√©voir la gestion d'erreurs\n",
    "- **L'encodage est crucial** : Les caract√®res sp√©ciaux causent souvent des probl√®mes\n",
    "- **La robustesse prime** : Un code qui g√®re les exceptions est essentiel\n",
    "- **L'exploration avant tout** : Comprendre ses donn√©es avant de mod√©liser\n",
    "\n",
    "### üöÄ Prochaines √©tapes :\n",
    "\n",
    "**Session 2 - R√©gression et Pr√©diction**\n",
    "- Nettoyer et pr√©parer les donn√©es BAC\n",
    "- Cr√©er un mod√®le de r√©gression pour pr√©dire les notes\n",
    "- Appliquer Ridge et Lasso pour la r√©gularisation\n",
    "- √âvaluer avec RMSE, MAE, R¬≤\n",
    "\n",
    "---\n",
    "\n",
    "**üìß Contact :** mohamed.beydia@vela-learning.com  \n",
    "**üåê Vela Learning :** [https://vela-learning.com](https://vela-learning.com)  \n",
    "**üéì SupNum Nouakchott**\n",
    "\n",
    "**üéâ Session 1 termin√©e avec succ√®s ! Donn√©es charg√©es et explor√©es ! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
